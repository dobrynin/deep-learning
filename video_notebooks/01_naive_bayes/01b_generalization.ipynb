{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training And Test Sets\n",
    "\n",
    "The way we are measuring performance is a little too leniant. We are supposed to train a model that predicts whether future emails are ham/spam, but we're measuring performance on the *training set*. This is often problematic because sometimes models will just \"memorize\" the training dataset in a way that doesn't lead to any future good performance.\n",
    "\n",
    "For instance, say our model was able to record an exact map from a bag of words to a label of ham or spam. Then, since every email in the training set probably has a unique bag of words, the model would be able to just record an exact mapping of email to label. But when we go to evaluate new emails, new emails won't match any of those bags of words. Thus there would be no ability to predict labels for future emails.\n",
    "\n",
    "To make sure our model *generalizes* well, it is common to split our data into two parts: the *training set* and the *test set*. The training set is fed to the machine learning algorithm, and then we use the test set to measure performance of the learned model. Since the ML algorithm never has seen the test set before, this should be a fair test of its ability to detect spam.\n",
    "\n",
    "Let's train on 80% of the data, and leave 20% for testing. There is a conflict of interest when picking these proportions. The more data you train on, the better your model will be. But the more data in your testing set, the more accurate your estimate on how the model will generalize.\n",
    "\n",
    "When you have more data, you might use more less for testing, figuring this amount will still be sufficient. On the other hand, 80/20 is a pretty common ratio to use.\n",
    "\n",
    "There are fancy techniques like [cross-validation][0], but I won't talk about those here.\n",
    "\n",
    "[0]: https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Generalizes Well\n",
    "\n",
    "As you can see, the naive bayes model has generalized very well to the test set. The recall numbers at each false positive rate are all mostly in line with the rates calculated over the entire dataset. That shows that we aren't just memorizing the training dataset.\n",
    "\n",
    "Overfitting is not normally a major problem for Naive Bayes models. This is because Naive Bayes is very simple. The way overfitting normally happens with other models is that parameters are carefully set so that if just the right set of features (those of the memorized example) come in, then the right answer goes out (the label of the memorized example).\n",
    "\n",
    "To do this, a model typically needs to coordinate many parameters so they are \"just right\" for the training example.\n",
    "\n",
    "However, the Naive Bayes model does no such coordination. It sets each parameter seperately. It has no way to tweak parameters so they have combined effects that are any different than their individual effects.\n",
    "\n",
    "Just because Naive Bayes is good at avoiding overfitting doesn't mean that it always gives high performance. It relies on this assumption that we *know* isn't true: that the presence of a word $w_i$ is independent of a word $w_j$ given the class of the example. In many contexts, understanding these interaction effects will be very important.\n",
    "\n",
    "For instance, if we want to classify emails based on *sentiment*, then words like \"good\", \"great\", \"awesome\" are positive signals, while \"terrible\", \"bad\", \"awful\" are negative signals. But what about \"This movie is not good?\" How is the Naive Bayes model supposed to know this is negative? It can't just make \"not\" a very negative word, because I could also say: \"This movie is not bad.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Versus Variance\n",
    "\n",
    "We will later explore a classic tradeoff of machine learning models: *bias* versus *variance*. We say a model class is very *biased* if it imposes a very simple, inflexible structure of model. For instance, a model class of linear models is much more biased than the model class of all polynomial functions.\n",
    "\n",
    "On the other hand, we say a model class has *high* variance if we learn very different models depending on what data we feed it. For instance: if I feed the first, third, et cetera emails into the Naive Bayes model, I will get mostly the same model as feeding in the second, fourth, et cetera emails. We say Naive Bayes has *low* variance. The idea is that the Naive Bayes model doesn't vary much in what sample you feed it.\n",
    "\n",
    "Models that exhibit high variance do so because they have more *capacity*. That means: they can capture more complex relationships. This additional flexibility often allows the model to capture relationships that \"aren't really there.\"\n",
    "\n",
    "We saw an example of this before with fitting the line to the Gaussian noise. A relationship like this is called *spurious*. Luckily, a linear model is very biased (has low capacity), so the spurious relationship the linear model thinks it found in the noise is very weak.\n",
    "\n",
    "The ability to capture spurious relationships often means that a model *thinks* it is doing a good job on the training dataset, but when we test it on the test dataset, the model fails badly. This happens because the things it thought it learned turn out to be false.\n",
    "\n",
    "All else equal, you want to minimize bias in your model class. Bias is basically simplifying assumptions about what kind of model explains the data. But those assumptions are typically not quite correct, and so your model may not perform well if your assumptions are too simplistic.\n",
    "\n",
    "On the other hand, when you have small amounts of data, you will prefer models with less capacity, because training a high capacity model with small amounts of data leads to high variance in outcome. Basically: there isn't enough data to convince the model not to use its additional capacity to model noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
