{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to find minima of functions. Let's do the exercise where we pretend we know `THETA0` and then just find `THETA1`.\n",
    "\n",
    "First, let me generate the dataset for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "THETA0 = 100\n",
    "THETA1 = 5.0\n",
    "NOISE_STDDEV = 25\n",
    "\n",
    "x = np.random.uniform(low = 0, high = 100, size = 100)\n",
    "y = THETA0 + THETA1 * x\n",
    "y += np.random.normal(scale = NOISE_STDDEV, size = 100)\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.ylim(ymin = 0)\n",
    "\n",
    "x_range = np.arange(0, 100, 5.0)\n",
    "plt.plot(x_range, THETA0 + THETA1 * x_range, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, your job is to plot the error function as a function of $\\theta_1$ for a fixed $\\theta_0 = 100$.\n",
    "\n",
    "First, write a function called `sse_error`. This should find the SSE error for a given `theta1`. You may use `x`, `y`, and `THETA0`. I've given you a hint for checking the function.\n",
    "\n",
    "Next, write a function called `sse_errors(theta1_values)`. This should create an empty numpy array of \"return values\" using `np.zeros`. How long should this array be? It should be as long as `theta1_values` is.\n",
    "\n",
    "Next, iterate through `theta1_values`. Calculate the `sse_error` for each `theta1_values[idx]`. Store this in the return values array. Finally, return the array.\n",
    "\n",
    "Plot the `sse_errors(theta1_values)` against the `theta1_values`. You should see a parabolic curve that has a minimum at about 5.0. (The minimum may not be exactly 5.0, because of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_error(theta1):\n",
    "    # you may use x, y, and THETA0 here.\n",
    "    pass\n",
    "\n",
    "# Should be 64360.1077567.\n",
    "print(\n",
    "    sse_error(5.0)\n",
    ")\n",
    "\n",
    "def sse_errors(theta1_values):\n",
    "    pass\n",
    "\n",
    "theta1_values = np.arange(0, 10, 0.1)\n",
    "plt.plot(theta1_values, sse_errors(theta1_values), '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next goal is to find the best $\\hat\\theta_1$ that minimizes the squared error.\n",
    "\n",
    "To do this, **first** write a function `sse_error_deriv_wrt_theta1(theta0, theta1, x, y)`. You will need the formula for this derivative. You can calculate this from:\n",
    "\n",
    "\\\\[\n",
    "E(\\theta_0, \\theta_1) = \\sum_{i=0}^N ((\\theta_0 + \\theta_1 x_i) - y_i)^2\n",
    "\\\\\n",
    "\\frac{\\partial E}{\\partial \\theta_1}(\\theta_0, \\theta_1) = \\sum_{i=0}^N \\text{(what goes here?)}\n",
    "\\\\]\n",
    "\n",
    "Two hints: (1) remember the polynomial rule that $f(x) = x^k \\Rightarrow f'(x) = k x^{k - 1}$, and (2) the chain rule: $f(x) = g(h(x)) \\Rightarrow f'(x) = g'(h(x))h'(x)$.\n",
    "\n",
    "**Next**, write the function `sse_error_2nd_deriv_wrt_theta1(theta0, theta1, x, y)`.\n",
    "\n",
    "Both these functions can be written in a vector form with no loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_error_deriv_wrt_theta1(theta0, theta1, x, y):\n",
    "    pass\n",
    "\n",
    "def sse_error_2nd_deriv_wrt_theta1(theta0, theta1, x, y):\n",
    "    pass\n",
    "\n",
    "print(\n",
    "    sse_error_deriv_wrt_theta1(THETA0, 5.0, x, y)\n",
    ")\n",
    "# => should be -42846.3348768\n",
    "\n",
    "print(\n",
    "    sse_error_2nd_deriv_wrt_theta1(THETA0, 5.0, x, y)\n",
    ")\n",
    "# => should be 613303.660271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these functions, and a starting point of `theta0 = 100.0` and `theta1 = 0.0` , use the derivative and second derivative to calculate the next guess for `theta1` according to Newton's Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = 100.0\n",
    "theta1 = 0.0\n",
    "print(\n",
    "    # This is your job!\n",
    ")\n",
    "# => Should be about 5.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
