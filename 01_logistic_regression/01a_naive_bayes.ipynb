{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Our task for today will be to classify emails as spam or not spam. We sill use the Enron Email Dataset. The dataset contains email text along with a label of whether that text was spam or not.\n",
    "\n",
    "First, let's load the dataset, and look at an example too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Run this cell to define useful Latex macros)**\n",
    "\\\\[\n",
    "\\newcommand{\\card}[1]{\\left\\lvert#1\\right\\rvert}\n",
    "\\newcommand{\\condbar}[0]{\\,\\big|\\,}\n",
    "\\newcommand{\\eprob}[1]{\\widehat{\\text{Pr}}\\left[#1\\right]}\n",
    "\\newcommand{\\norm}[1]{\\left\\lvert\\left\\lvert#1\\right\\rvert\\right\\rvert}\n",
    "\\newcommand{\\prob}[1]{\\text{Pr}\\left[#1\\right]}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarfile already downloaded!\n",
      "Tarfile already extracted!\n",
      "Dataset already processed!\n",
      "\n",
      ">>> HAM EMAIL:\n",
      "========================================================================\n",
      "Subject: mcmullen gas for 11 / 99\n",
      "jackie ,\n",
      "since the inlet to 3 river plant is shut in on 10 / 19 / 99 ( the last day of\n",
      "flow ) :\n",
      "at what meter is the mcmullen gas being diverted to ?\n",
      "at what meter is hpl buying the residue gas ? ( this is the gas from teco ,\n",
      "vastar , vintage , tejones , and swift )\n",
      "i still see active deals at meter 3405 in path manager for teco , vastar ,\n",
      "vintage , tejones , and swift\n",
      "i also see gas scheduled in pops at meter 3404 and 3405 .\n",
      "please advice . we need to resolve this as soon as possible so settlement\n",
      "can send out payments .\n",
      "thanks\n",
      "\n",
      ">>> SPAM EMAIL:\n",
      "========================================================================\n",
      "Subject: re : rdd , the auxiliary iturean\n",
      "free cable @ tv\n",
      "dabble bam servomechanism ferret canopy bookcase befog seductive elapse ballard daphne acrylate deride decadent desolate else sequestration condition ligament ornately yaqui giblet emphysematous woodland lie segovia almighty coffey shut china clubroom diagnostician\n",
      "cheer leadsman abominate cambric oligarchy mania woodyard quake tetrachloride contiguous welsh depressive synaptic trauma cloister banks canadian byroad alexander gnaw annette charlie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import lib.download\n",
    "lib.download.run()\n",
    "\n",
    "import lib.dataset\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "print()\n",
    "print(\">>> HAM EMAIL:\")\n",
    "print(\"=\" * 72)\n",
    "print(RAW_DATASET.ham_emails[5].text_content())\n",
    "\n",
    "print()\n",
    "print(\">>> SPAM EMAIL:\")\n",
    "print(\"=\" * 72)\n",
    "print(RAW_DATASET.spam_emails[10].text_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the email text is all lower case, and each *token* (words, but also symbols like \"@\") is seperated by a space. The subject line is not technically part of the email body, but I will leave it in anyway.\n",
    "\n",
    "For the purposes of our algorithm, we will convert emails into a set of words, throwing away the order of the words, and also how frequently they occur in the email. Every token will be represented with an integer, rather than the word itself.\n",
    "\n",
    "We will represent whether an email is spam or not with a 1 for spam and a 0 for not spam. This is called the *label*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SortedSet([0, 7, 13, 27, 69, 209, 306, 679, 1076, 1466, 1492, 3200, 3498, 3880, 4518, 5332, 5673, 6040, 6075, 7845, 10796, 11378, 11981, 12835, 14532, 16407, 17924, 20486, 20487, 20488, 20489, 20490, 20491, 20492, 20493, 20494, 20495, 20496, 20497, 20498, 20499, 20500, 20501, 20502, 20503, 20504, 20505, 20506, 20507, 20508, 20509, 20510, 20511, 20512, 20513, 20514, 20515, 20516, 20517, 20518, 20519, 20520, 20521, 20522, 20523, 20524], key=None, load=1000)\n",
      "SortedSet([',', ':', '@', 'Subject:', 'abominate', 'acrylate', 'alexander', 'almighty', 'annette', 'auxiliary', 'ballard', 'bam', 'banks', 'befog', 'bookcase', 'byroad', 'cable', 'cambric', 'canadian', 'canopy', 'charlie', 'cheer', 'china', 'cloister', 'clubroom', 'coffey', 'condition', 'contiguous', 'dabble', 'daphne', 'decadent', 'depressive', 'deride', 'desolate', 'diagnostician', 'elapse', 'else', 'emphysematous', 'ferret', 'free', 'giblet', 'gnaw', 'iturean', 'leadsman', 'lie', 'ligament', 'mania', 'oligarchy', 'ornately', 'quake', 'rdd', 're', 'seductive', 'segovia', 'sequestration', 'servomechanism', 'shut', 'synaptic', 'tetrachloride', 'the', 'trauma', 'tv', 'welsh', 'woodland', 'woodyard', 'yaqui'], key=None, load=1000)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(RAW_DATASET.spam_emails[10].codes)\n",
    "print(RAW_DATASET.spam_emails[10].words())\n",
    "print(RAW_DATASET.spam_emails[10].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the preprocessing of the dataset *featurization*. The machine learning algorithm will interact with the *featurized* emails (the set of numbers and the 0/1 label), rather than the raw emails themselves.\n",
    "\n",
    "Featurization is an important part of data preparation. For instance, we saw previously in the linear regression notebooks that it was very helpful to normalize the mean and variance of continuous valued variables. Other featurization techniques are to lowercase words, to normalize whitespace. Sometimes *stemming* is done: this tries to normalize a word like \"robots\" to \"robot\", removing the \"s\". The \"stem\" is the base word. This is done because often the plethora of minor variants of words can be confusing to ML algorithms.\n",
    "\n",
    "It is not uncommon to throw away word order and word counts. This representation of text is called the *bag of words model*. Obviously a lot of information is lost with this representation. For some tasks like document retrieval based on keyword matching, the bag of words model can still be useful. For tasks like spam/not-spam bag of words performs well.\n",
    "\n",
    "For tasks which need deeper *semantic* understanding of a document (understanding what it means), we would want to use techniques which can exploit the information contained in the word ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Probabilities\n",
    "\n",
    "To detect which emails are spam and which aren't, we will use the observation that some words are more probable to appear in a spam email rather than in a non-spam email. For instance, I suspect that \"offer\" is more probable to appear in a spam email than a non-spam email. In notation:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    ">\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "\\\\]\n",
    "\n",
    "Now, what I really want to know is what is the probability that an email is spam if it contains the word \"offer\". That is, I want to calculate:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "\\\\]\n",
    "\n",
    "To do so, I will use *Bayes' Rule*:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\wedge \\text{OFFER} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "    \\cdot\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "It is frequently convenient to consider the *odds* that something is true, rather than the probability. If the probability of $X$ is $p$, then the *odds* of $X$ are $\\frac{p}{1-p}$. For instance, a probability of $0.66$ corresponds to an odds of $2$, sometimes written $2:1$.\n",
    "\n",
    "To calculate the odds that an email is spam if it has the word offer in it, first apply Bayes' Rule again to the probability that the email is not spam:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 0 \\condbar \\text{OFFER} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "    \\cdot\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Last, let's compute the odds:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0 \\condbar \\text{OFFER} = 1}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "The second factor in the product I will call the *feature probability ratio*. It is the ratio in feature probability conditional on $SPAM = 1$ versus when $SPAM = 0$.\n",
    "\n",
    "Alright! Let's do this with code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_probability_ratio': 4.154271138165185}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lib.dataset\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "feature_probabilities = RAW_DATASET.feature_probabilities()\n",
    "feature_probabilities.code_prob_ratio(\n",
    "    code = RAW_DATASET.word_encoding_dictionary.word_to_code('offer')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this shows is that the odds that an email is spam are $4.15$ times greater if we know that it contains the word \"offer.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Quantities Can Be Inaccurate\n",
    "\n",
    "**TODO**: Careful about the use of the word odds here.\n",
    "To calculate the odds, we are using the counts observed in the dataset. We call this the *empirical* odds: empirical means \"known from experience or observation.\" Likewise, an *empirical* probability is one calculated using observed data.\n",
    "\n",
    "When there isn't very much data, an empirical quantity will be suspect. See below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts | {'ham_count': 0, 'spam_count': 1}\n",
      "Feature Probability Ratio | {'feature_probability_ratio': inf}\n"
     ]
    }
   ],
   "source": [
    "import lib.dataset\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "code = RAW_DATASET.word_encoding_dictionary.word_to_code('bacterial')\n",
    "\n",
    "print(f\"Counts | {feature_probabilities.code_counts[code]}\")\n",
    "print(f\"Feature Probability Ratio | {feature_probabilities.code_prob_ratio(code)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, only one email had the word \"bacterial\" in it. It was a spam email. Therefore, the empirical probability:\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{SPAM} = 1 \\condbar \\text{BACTERIAL} = 1} = 1.0\\\\\n",
    "\\eprob{\\text{SPAM} = 0 \\condbar \\text{BACTERIAL} = 1} = 0.0\n",
    "\\\\]\n",
    "\n",
    "Here I'm trying to make clear that this probability is an *estimate* of the *true* probability using the empirical probability. Nobody thinks that the presence of the word \"bacteria\" guarantees an email is spam. In a case like this where the *reach* of a feature is only one example, the empirical probability can only be either $0.0$ or $1.0$. Both examples are completely extreme.\n",
    "\n",
    "Even though the empirical probability to converge to the true probability with more observations, the empirical probability may be very wrong when the sample size is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discarding Low Reach Features\n",
    "\n",
    "How do we deal with this problem? There is more than one way. Let's adopt the simplest: let's throw away all features with a reach of less than twenty examples.\n",
    "\n",
    "To verify that the remaining features seem to be good, let's look at the top indicators that an email is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077 | 2004 | reach: {'ham_count': 1, 'spam_count': 121} | feature_probability_ratio: 217.47:1\n",
      "5969 | microsoft | reach: {'ham_count': 11, 'spam_count': 98} | feature_probability_ratio: 16.01:1\n",
      "3104 | investment | reach: {'ham_count': 11, 'spam_count': 96} | feature_probability_ratio: 15.68:1\n",
      "3522 | results | reach: {'ham_count': 18, 'spam_count': 98} | feature_probability_ratio: 9.78:1\n",
      "370 | v | reach: {'ham_count': 26, 'spam_count': 134} | feature_probability_ratio: 9.26:1\n",
      "3951 | million | reach: {'ham_count': 20, 'spam_count': 97} | feature_probability_ratio: 8.72:1\n",
      "680 | stop | reach: {'ham_count': 31, 'spam_count': 147} | feature_probability_ratio: 8.52:1\n",
      "3900 | software | reach: {'ham_count': 22, 'spam_count': 101} | feature_probability_ratio: 8.25:1\n",
      "5621 | 80 | reach: {'ham_count': 23, 'spam_count': 104} | feature_probability_ratio: 8.13:1\n",
      "4002 | dollars | reach: {'ham_count': 26, 'spam_count': 113} | feature_probability_ratio: 7.81:1\n",
      "4611 | remove | reach: {'ham_count': 28, 'spam_count': 110} | feature_probability_ratio: 7.06:1\n",
      "3462 | stock | reach: {'ham_count': 22, 'spam_count': 84} | feature_probability_ratio: 6.86:1\n",
      "4795 | removed | reach: {'ham_count': 22, 'spam_count': 83} | feature_probability_ratio: 6.78:1\n",
      "2772 | money | reach: {'ham_count': 50, 'spam_count': 187} | feature_probability_ratio: 6.72:1\n",
      "2737 | world | reach: {'ham_count': 34, 'spam_count': 124} | feature_probability_ratio: 6.55:1\n",
      "2512 | save | reach: {'ham_count': 35, 'spam_count': 125} | feature_probability_ratio: 6.42:1\n",
      "2518 | http | reach: {'ham_count': 135, 'spam_count': 475} | feature_probability_ratio: 6.32:1\n",
      "570 | quality | reach: {'ham_count': 29, 'spam_count': 101} | feature_probability_ratio: 6.26:1\n",
      "4517 | canada | reach: {'ham_count': 23, 'spam_count': 79} | feature_probability_ratio: 6.17:1\n",
      "3347 | low | reach: {'ham_count': 31, 'spam_count': 106} | feature_probability_ratio: 6.15:1\n"
     ]
    }
   ],
   "source": [
    "import lib.dataset\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "filtered_feature_probabilities = RAW_DATASET.feature_probabilities().filter(reach_limit = 100)\n",
    "\n",
    "def top_features(fps, limit = 20):\n",
    "    codes = list(fps.code_counts.keys())\n",
    "    code_prob_ratios = [{\n",
    "        'code': code,\n",
    "        'reach': fps.code_counts[code],\n",
    "        'feature_probability_ratio': fps.code_prob_ratio(code).feature_probability_ratio\n",
    "    } for code in codes]\n",
    "    code_prob_ratios.sort(key = lambda code_prob_ratio: -code_prob_ratio['feature_probability_ratio'])\n",
    "    return code_prob_ratios[:limit]\n",
    "\n",
    "for code_prob_ratio in top_features(filtered_feature_probabilities):\n",
    "    code, reach, feature_probability_ratio = (\n",
    "        code_prob_ratio['code'],\n",
    "        code_prob_ratio['reach'],\n",
    "        code_prob_ratio['feature_probability_ratio']\n",
    "    )\n",
    "    word = RAW_DATASET.word_encoding_dictionary.code_to_word(code)\n",
    "    print(f\"{code} | {word} | reach: {reach} | feature_probability_ratio: {feature_probability_ratio:0.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That list looks okay. It is a little bizarre to see 2004 up there. Let's move on for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairs Of Features Have Low Reach\n",
    "\n",
    "We want to use more than just a single word to characterize whether an email is spam. For instance, I want:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1 \\wedge \\text{LIMITED} = 1}\n",
    "\\\\]\n",
    "\n",
    "Now, it is possible to count how many emails have *both* the words \"limited\" and \"offer.\" We could then count how many of those emails are spam. From these two counts we could calculate the empirical probability\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1 \\wedge \\text{LIMITED} = 1}\n",
    "\\\\]\n",
    "\n",
    "However, we're just going to go back to our old problem. There may well not be enough emails that feature both words to estimate this probability properly. Even fewer examples will contain the three words \"offer\", \"limited\", and \"investment\". And our ultimate goal is try to estimate:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{all the words in the email}}\n",
    "\\\\]\n",
    "\n",
    "Since each new email likely represents a unique bag of words, there is almost no chance we've ever seen an email exactly like this. And even if we've seen one, that's not enough samples to reliably estimate this probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence\n",
    "\n",
    "**TODO**: Conversion from odds is invalid here.\n",
    "\n",
    "We want to avoid ever conditioning on more than one feature, because when we condition on pairs of features, the number of examples with both those features will be far smaller than the number of examples with one or the other.\n",
    "\n",
    "Let's consider the words \"investment\" and \"quality\". From the above table, we have:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\eprob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1} &= \\frac{8.73}{8.73 + 1.0} = 0.89\\\\\n",
    "\\eprob{\\text{SPAM} = 1\\condbar \\text{QUALITY} = 1} &= \\frac{3.48}{3.48 + 1.0} = 0.77\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Here I have used the formula for converting odds back to probabilities. Because the reach of the \"investment\" and \"quality\" features is high, these estimates are probably pretty good. However, we want:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "\\\\]\n",
    "\n",
    "And we know that the empirical probability is likely a poor estimate of the true probability because we expect the reach of the pair of features together to be low.\n",
    "\n",
    "Let's try anyway and see where we get. Let's apply Bayes' rule as before:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "The denominator may be difficult to estimate because it involves the conjunction of the two features. But we can get rid of this if we use the odds like before:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Now, wouldn't it beautiful if:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "If this were true, it would say we could calculate the combined effect of having both \"investment\" and \"quality\" in an email by multiplying the two effects of having (1) \"investment\" and (2) \"quality\" in an email. Since we have good estimates of those individual odds ratio, we'll have a good estimate of the combined effect.\n",
    "\n",
    "When *would* this be true? Well, consider:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\\n",
    "=\n",
    "\\\\\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "\\\\]\n",
    "\n",
    "What did I just do here? Well: I just applied Bayes' rule. So this shows that we'll have our desired \"compounding\" of effects if:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "This property is called *conditional independence*. We say that the presence of the word \"quality\" is conditionally independent from the presence of the word \"investment\", *given* that we know the email to be spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples When Unconditional Independence Is Violated\n",
    "\n",
    "Let me show that the presence of \"quality\" and \"investment\" are not *unconditionally* independent. That is:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{INVESTMENT} = 1}\n",
    "\\ne\n",
    "\\prob{\\text{QUALITY} = 1}\n",
    "\\\\]\n",
    "\n",
    "Here's why this isn't true in general. The presence of the word \"investment\" suggests that the email is spam. And, if the email is spam, then it is more likely to contain the word \"quality\" than the average email. That means that the presence of the word \"investment\" makes the presence of the word \"quality\" more likely. Which is to say: the presence of \"investment\" and the presence of \"quality\" are not independent of each other.\n",
    "\n",
    "However, what if I already know that an email is spam? Normally, the presence of the word \"investment\" would indicate an email is spam, but I already know that. Therefore the presence of the word \"investment\" doesn't indicate the word \"quality\" is any more likely to be present through its indication that an email is spam. When we are conditioning on both $\\text{SPAM} = 1$ and $\\text{INVESTMENT} = 1$, the second piece of information loses its value in informing us about $\\text{SPAM}$, since we already know the value of that variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples When Conditional Independence Is Violated\n",
    "\n",
    "The question then becomes: does the presence of the word investment change the probability of \"quality\" appearing for *any other* reason? Now, it may be possible that the words \"quality\" and \"investment\" often appear in the same spam emails because \"investment\" frequently appears as part of the compound phrase \"a quality investment\". If that were true, it may be that:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    ">\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "On the other hand, considering another pair of words, it may be that \"baldness\" is less likely given the presence of the word \"investment\" in spam emails. That might be because a spam email either pitches an investment or a baldness cure, but not typically both. In that case, the presence of \"investment\" might *inhibit* \"baldness.\" If this is true:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "<\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Just Pretend\n",
    "\n",
    "We've seen that, independent of their effect at hinting at whether an email is spam, a word like \"investment\" may (1) indicate the presence of \"quality\" or (2) indicate the absence of \"baldness.\"\n",
    "\n",
    "However, let's just pretend like that didn't happen. Let's just assume:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\\\\\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "We know this probably isn't true, but let's just pretend. The advantage is that we have pretty good estimates on quantities like $\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}$. And doing so let's us combine them in a simple (if somewhat unjustified) way:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "More generally, consider email contains the words $W_{i_1}, \\ldots, W_{i_k}$. I have used $i_1,\\ldots,i_k$ to represent that these are a subset of $k$ words in the set of all words. If there are $\\card{W}$ words, then the indices range over $1,\\ldots,\\card{W}$, but unless the email contains all words $k\\ne\\card{W}$.\n",
    "\n",
    "Anyway, if the email contains these words, then:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{W_{i_1} = 1, \\ldots, W_{i_k} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_1} = 1, \\ldots, W_{i_k} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{W_{i_1} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_1} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_{i_k} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_k} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Okay! Let's try this out and see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate 0.01 | Recall 0.64\n",
      "False Positive Rate 0.02 | Recall 0.75\n",
      "False Positive Rate 0.04 | Recall 0.87\n",
      "False Positive Rate 0.08 | Recall 0.95\n",
      "False Positive Rate 0.16 | Recall 1.00\n"
     ]
    }
   ],
   "source": [
    "import lib.dataset\n",
    "from lib.naive_bayes_model import NaiveBayesModel\n",
    "\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    RAW_DATASET.feature_probabilities().filter(reach_limit = 100),\n",
    "    use_negative_features = False\n",
    ")\n",
    "FALSE_POSITIVE_RATES = [0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "for (false_positive_rate, result) in model.recall_for_false_positive_rates(RAW_DATASET, FALSE_POSITIVE_RATES):\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.2f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *false positive rate* is the percentage of ham emails that were marked as spam. *Recall* is the percentage of percentage of spam emails that were identified as spam. Recall is the same as the *true positive rate*. Obviously the ideal is to have a false positive rate of zero and a recall of one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Absence Matters Too!\n",
    "\n",
    "**TODO**: Explain why this makes no difference.\n",
    "\n",
    "See that `use_negative_features = False`? Right now we've only been using words that were observed: words whose presence indicates spam or not spam.\n",
    "\n",
    "Another question is what about the *absence* of words? What if all spam emails contain a word? If it is absent, then we know this is a ham email. But our calculation isn't using that kind of information. The way we've written it, it's as if we know that some words are present, but *don't know* whether the other words are *absent*. So let's rewrite slightly. Assume that $w_i = 1$ when the word $W_i$ is present, and $w_i = 0$ otherwise. Then:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{W_1 = w_1, \\ldots, W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = w_1, \\ldots, W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{W_1 = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Let's see if the use of these features can help our model predict spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate 0.01 | Recall 0.64\n",
      "False Positive Rate 0.02 | Recall 0.75\n",
      "False Positive Rate 0.04 | Recall 0.87\n",
      "False Positive Rate 0.08 | Recall 0.95\n",
      "False Positive Rate 0.16 | Recall 1.00\n"
     ]
    }
   ],
   "source": [
    "import lib.dataset\n",
    "from lib.naive_bayes_model import NaiveBayesModel\n",
    "\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    RAW_DATASET.feature_probabilities().filter(reach_limit = 100),\n",
    "    use_negative_features = True\n",
    ")\n",
    "FALSE_POSITIVE_RATES = [0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "for (false_positive_rate, result) in model.recall_for_false_positive_rates(RAW_DATASET, FALSE_POSITIVE_RATES):\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.2f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training And Test Sets\n",
    "\n",
    "Wow, that's way better! However, the way we are measuring performance is a little too leniant. We are supposed to train a model that predicts whether future emails are ham/spam, but we're measuring performance on the *training set*. This is often problematic because sometimes models will just \"memorize\" the training dataset in a way that doesn't lead to any future good performance.\n",
    "\n",
    "For instance, say our model was able to record an exact map from a bag of words to a label of ham or spam. Then, since every email in the training set probably has a unique bag of words, the model would be able to just record an exact mapping of email to label. But when we go to evaluate new emails, new emails won't match any of those bags of words. Thus there would be no ability to predict labels for future emails.\n",
    "\n",
    "To make sure our model *generalizes* well, it is common to split our data into two parts: the *training set* and the *test set*. The training set is fed to the machine learning algorithm, and then we use the test set to measure performance of the learned model. Since the ML algorithm never has seen the test set before, this should be a fair test of its ability to detect spam.\n",
    "\n",
    "Let's train on 80% of the data, and leave 20% for testing. There is a conflict of interest when picking these proportions. The more data you train on, the better your model will be. But the more data in your testing set, the more accurate your estimate on how the model will generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_number of emails: 5172\n",
      "number of training emails: 4181\n",
      "number of test emails: 991\n",
      "False Positive Rate 0.01 | Recall 0.69\n",
      "False Positive Rate 0.02 | Recall 0.75\n",
      "False Positive Rate 0.04 | Recall 0.82\n",
      "False Positive Rate 0.08 | Recall 0.91\n",
      "False Positive Rate 0.16 | Recall 0.98\n"
     ]
    }
   ],
   "source": [
    "import lib.dataset\n",
    "from lib.naive_bayes_model import NaiveBayesModel\n",
    "\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "(training_set, test_set) = RAW_DATASET.split(ratio = 0.80)\n",
    "\n",
    "print(f\"total_number of emails: {len(RAW_DATASET.ham_emails) + len(RAW_DATASET.spam_emails)}\")\n",
    "print(f\"number of training emails: {len(training_set.ham_emails) + len(training_set.spam_emails)}\")\n",
    "print(f\"number of test emails: {len(test_set.ham_emails) + len(test_set.spam_emails)}\")\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    training_set.feature_probabilities().filter(reach_limit = 100),\n",
    "    use_negative_features = True\n",
    ")\n",
    "FALSE_POSITIVE_RATES = [0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "for (false_positive_rate, result) in model.recall_for_false_positive_rates(test_set, FALSE_POSITIVE_RATES):\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.2f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Generalizes Well\n",
    "\n",
    "As you can see, the naive bayes model has generalized well to the test set. The recall numbers at each false positive rate are all mostly in line with the rates calculated over the entire dataset. That shows that we aren't just memorizing the training dataset.\n",
    "\n",
    "Overfitting is not normally a major problem for Naive Bayes models. This is because Naive Bayes is very simple. The way overfitting normally happens with other models is that parameters are carefully set so that if just the right set of features (those of the memorized example) come in, then the right answer goes out (the label of the memorized example).\n",
    "\n",
    "To do this, a model typically needs to coordinate many parameters so they are \"just right\" for the training example.\n",
    "\n",
    "However, the Naive Bayes model does no such coordination. It sets each parameter seperately. It has no way to tweak parameters so they have combined effects that are any different than their individual effects.\n",
    "\n",
    "Just because Naive Bayes is good at avoiding overfitting doesn't mean that it always gives high performance. It relies on this assumption that we *know* isn't true: that the presence of a word $w_i$ is independent of a word $w_j$ given the class of the example. In many contexts, understanding these interaction effects will be very important.\n",
    "\n",
    "For instance, if we want to classify emails based on *sentiment*, then words like \"good\", \"great\", \"awesome\" are positive signals, while \"terrible\", \"bad\", \"awful\" are negative signals. But what if I write you and say \"This movie is not good.\" How is the Naive Bayes model supposed to know this is negative? It can't just make \"not\" a very negative word, because I could also say: \"this movie is not bad.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Versus Variance\n",
    "\n",
    "We will later explore a classic tradeoff of machine learning models: *bias* versus *variance*. We say a model class is very *biased* if it imposes a very simple, inflexible structure of model. For instance, a model class of linear models is much more biased than the model class of all polynomial functions.\n",
    "\n",
    "On the other hand, we say a model class has high variance if we learn very different models depending on what data we feed it. For instance: if I feed the first, third, et cetera emails into the Naive Bayes model, I will get mostly the same model as feeding in the second, fourth, et cetera emails. We say Naive Bayes has low *variance*.\n",
    "\n",
    "Models that exhibit high variance do so because they have more *capacity*. That means: they can capture more complex relationships. This additional flexibility often allows the model to capture relationships that \"aren't really there.\" We saw this before with fitting the line to the Gaussian noise. A relationship like this is called *spurious*.\n",
    "\n",
    "The ability to capture spurious relationships often means that a model *thinks* it is doing a good job on the training dataset, but when we test it on the test dataset, the model fails badly. This happens because the things it thought it learned turn out to be false.\n",
    "\n",
    "All else equal, you want to minimize bias in your model class. Bias is basically simplifying assumptions about what kind of model explains the data. But those assumptions are typically not quite correct, and so your model can only do so good.\n",
    "\n",
    "On the other hand, when you have small amounts of data, you will prefer models with less capacity, because training a high capacity model with small amounts of data leads to high variance in outcome. Basically: there isn't enough data to convince the model not to use its additional capacity to model noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Probability Estimates Are Inaccurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes model is an example of a *probabilistic graphical model*. In particular, it is the simplest example of a *Bayesian Network*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_number of emails: 5172\n",
      "number of training emails: 4181\n",
      "number of test emails: 991\n",
      "1.0\n",
      "1.5\n",
      "2.33333333333\n",
      "4.0\n",
      "9.0\n",
      "[(0.5, {'limit': 0.5, 'expected_rate': 0.8464625715097166, 'true_rate': 0.98989898989899}), (0.59999999999999998, {'limit': 0.59999999999999998, 'expected_rate': 0.8589692389546726, 'true_rate': 0.9894736842105263}), (0.69999999999999996, {'limit': 0.69999999999999996, 'expected_rate': 0.8983776911209184, 'true_rate': 0.9875}), (0.79999999999999993, {'limit': 0.79999999999999993, 'expected_rate': 0.9536110350371055, 'true_rate': 1.0}), (0.89999999999999991, {'limit': 0.89999999999999991, 'expected_rate': 0.9766938702903117, 'true_rate': 1.0})]\n"
     ]
    }
   ],
   "source": [
    "import lib.dataset\n",
    "RAW_DATASET = lib.dataset.RawDataset.get()\n",
    "\n",
    "(training_set, test_set) = RAW_DATASET.split(ratio = 0.80)\n",
    "\n",
    "from lib.naive_bayes_model import NaiveBayesModel\n",
    "\n",
    "print(f\"total_number of emails: {len(RAW_DATASET.ham_emails) + len(RAW_DATASET.spam_emails)}\")\n",
    "print(f\"number of training emails: {len(training_set.ham_emails) + len(training_set.spam_emails)}\")\n",
    "print(f\"number of test emails: {len(test_set.ham_emails) + len(test_set.spam_emails)}\")\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    training_set.feature_probabilities().filter(reach_limit = 100),\n",
    "    use_negative_features = False\n",
    ")\n",
    "\n",
    "print(model.spam_probability_at_different_scores(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAACGCAYAAACfQY77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1156cd5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import examples.pgm_diagram_example\n",
    "\n",
    "examples.pgm_diagram_example.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Explain PGM.\n",
    "\n",
    "**TODO**: Show that $\\prob{C \\condbar w_i}$ is inaccurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
