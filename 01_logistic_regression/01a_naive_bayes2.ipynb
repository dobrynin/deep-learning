{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Our task for today will be to classify emails as spam or not spam. We sill use the [Enron Email Corpus](https://en.wikipedia.org/wiki/Enron_Corpus). The dataset contains email text along with a label of whether that text was spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Run this cell to define useful Latex macros)**\n",
    "\\\\[\n",
    "\\newcommand{\\card}[1]{\\left\\lvert#1\\right\\rvert}\n",
    "\\newcommand{\\condbar}[0]{\\,\\big|\\,}\n",
    "\\newcommand{\\eprob}[1]{\\widehat{\\text{Pr}}\\left[#1\\right]}\n",
    "\\newcommand{\\norm}[1]{\\left\\lvert\\left\\lvert#1\\right\\rvert\\right\\rvert}\n",
    "\\newcommand{\\prob}[1]{\\text{Pr}\\left[#1\\right]}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we do a number of things:\n",
    "\n",
    "1. We write a class called `WordEncodingDictionary` that will assign a numeric \"code\" to each English word. For instance, \"offer\" might have the code 123. Nodes can be more efficiently stored than words. The `WordEncodingDictionary` will keep track of what codes correspond to what words, and vice versa.\n",
    "2. We write an `Email` class. It has a method to read the email contents from the filesystem.\n",
    "3. We define a `Dataset` class. It will keep track of our `WordEncodingDictionary`, and it will have two lists of `Email`s: of ham `Email`s and spam `Email`s.\n",
    "4. We write a bunch of methods to download the Enron dataset, unzip it, and build the dataset by encoding the emails into a set of integers: one for each unique word in the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "DATA_DIR = os.path.join(\n",
    "    os.getcwd(),\n",
    "    \"data/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sortedcontainers import SortedSet\n",
    "\n",
    "# WordEncodingDictionary keeps a bidirectional map between numeric codes and the words they stand for.\n",
    "class WordEncodingDictionary:\n",
    "    def __init__(self):\n",
    "        self.word_to_code_dict = {}\n",
    "        self.code_to_word_dict = {}\n",
    "\n",
    "    def word_to_code(self, word):\n",
    "        if word not in self.word_to_code_dict:\n",
    "            code = len(self.word_to_code_dict)\n",
    "            self.word_to_code_dict[word] = code\n",
    "            self.code_to_word_dict[code] = word\n",
    "\n",
    "        return self.word_to_code_dict[word]\n",
    "\n",
    "    def code_to_word(self, code):\n",
    "        if code not in self.code_to_word_dict:\n",
    "            raise f\"Code {code} not recorded!\"\n",
    "\n",
    "        return self.code_to_word_dict[code]\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        codes = SortedSet()\n",
    "        for word in text.split():\n",
    "            codes.add(self.word_to_code(word))\n",
    "        return codes\n",
    "\n",
    "    def decode_codes_set(self, codes):\n",
    "        cls = type(codes)\n",
    "        return cls(map(self.code_to_word, codes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class Email:\n",
    "    def __init__(self, path, content, word_encoding_dictionary, label):\n",
    "        self.path = path\n",
    "        self.codes = word_encoding_dictionary.encode_text(content)\n",
    "        self.label = label\n",
    "        self.word_encoding_dictionary = word_encoding_dictionary\n",
    "\n",
    "    def text_content(self):\n",
    "        return type(self).read_text_content(self.path)\n",
    "\n",
    "    def words_set(self):\n",
    "        return self.word_encoding_dictionary.decode_codes_set(self.codes)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path, word_encoding_dictionary, label):\n",
    "        return Email(\n",
    "            path = path,\n",
    "            content = cls.read_text_content(path),\n",
    "            word_encoding_dictionary = word_encoding_dictionary,\n",
    "            label = label\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def read_text_content(cls, path):\n",
    "        full_path = os.path.join(DATA_DIR, path)\n",
    "        # Grr! Emails are encoded in Latin-1, not UTF-8. Python\n",
    "        # (rightly) freaks out.\n",
    "        with open(full_path, \"r\", encoding = \"iso-8859-1\") as f:\n",
    "            try:\n",
    "                return f.read()\n",
    "            except:\n",
    "                print(f\"Error with: {path}\")\n",
    "                raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pickle\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "            self, word_encoding_dictionary, ham_emails, spam_emails\n",
    "    ):\n",
    "        self.word_encoding_dictionary = word_encoding_dictionary\n",
    "        self.ham_emails = ham_emails\n",
    "        self.spam_emails = spam_emails\n",
    "\n",
    "    INSTANCE = None\n",
    "    @classmethod\n",
    "    def get(cls):\n",
    "        if not cls.INSTANCE:\n",
    "            with open(os.path.join(DATA_DIR, 'data.p'), 'rb') as f:\n",
    "                cls.INSTANCE = pickle.load(f)\n",
    "        return cls.INSTANCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarfile already downloaded!\n",
      "Tarfile already extracted!\n",
      "Dataset already processed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "ENRON_SPAM_URL = (\n",
    "    \"http://csmining.org/index.php/\"\n",
    "    \"enron-spam-datasets.html\"\n",
    "    \"?file=tl_files/Project_Datasets/Enron-Spam%20datasets/Preprocessed\"\n",
    "    \"/enron1.tar.tar\"\n",
    ")\n",
    "\n",
    "TAR_FILE_NAME = \"enron1.tar.tar\"\n",
    "ENRON_DATA_DIR_NAME = \"enron1\"\n",
    "\n",
    "def download_tarfile():\n",
    "    tarfile_path = os.path.join(DATA_DIR, TAR_FILE_NAME)\n",
    "    if os.path.isfile(tarfile_path):\n",
    "        print(\"Tarfile already downloaded!\")\n",
    "        return\n",
    "\n",
    "    print(\"Downloading enron1.tar.tar\")\n",
    "    urlretrieve(ENRON_SPAM_URL, tarfile_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_tarfile():\n",
    "    tarfile_path = os.path.join(DATA_DIR, TAR_FILE_NAME)\n",
    "    enron_data_dir = os.path.join(DATA_DIR, ENRON_DATA_DIR_NAME)\n",
    "    if os.path.isdir(enron_data_dir):\n",
    "        print(\"Tarfile already extracted!\")\n",
    "        return\n",
    "\n",
    "    print(\"Extracting enron1.tar.tar\")\n",
    "    os.system(f\"tar -xf {tarfile_path} -C {DATA_DIR}\")\n",
    "    print(\"Extraction complete!\")\n",
    "\n",
    "def read_emails_dir(word_encoding_dictionary, path, label):\n",
    "    emails = []\n",
    "    for email_fname in os.listdir(os.path.join(DATA_DIR, path)):\n",
    "        email_path = os.path.join(path, email_fname)\n",
    "        email = Email.read(\n",
    "            path = email_path,\n",
    "            word_encoding_dictionary = word_encoding_dictionary,\n",
    "            label = label\n",
    "        )\n",
    "        emails.append(email)\n",
    "\n",
    "    return emails\n",
    "\n",
    "def build_dataset():\n",
    "    word_encoding_dictionary = WordEncodingDictionary()\n",
    "    ham_emails = read_emails_dir(\n",
    "        word_encoding_dictionary = word_encoding_dictionary,\n",
    "        path = os.path.join(ENRON_DATA_DIR_NAME, \"ham\"),\n",
    "        label = 0\n",
    "    )\n",
    "    spam_emails = read_emails_dir(\n",
    "        word_encoding_dictionary = word_encoding_dictionary,\n",
    "        path = os.path.join(ENRON_DATA_DIR_NAME, \"spam\"),\n",
    "        label = 1\n",
    "    )\n",
    "\n",
    "    return Dataset(\n",
    "        word_encoding_dictionary = word_encoding_dictionary,\n",
    "        ham_emails = ham_emails,\n",
    "        spam_emails = spam_emails\n",
    "    )\n",
    "\n",
    "def save_dataset(dataset):\n",
    "    with open(\"data/data.p\", \"wb\") as f:\n",
    "        pickle.dump(dataset, f)\n",
    "\n",
    "def build_and_save_dataset():\n",
    "    if os.path.isfile(\"data/data.p\"):\n",
    "        print(\"Dataset already processed!\")\n",
    "        return\n",
    "\n",
    "    print(\"Reading and processing emails!\")\n",
    "    dataset = build_dataset()\n",
    "    save_dataset(dataset)\n",
    "    print(\"Dataset created!\")\n",
    "\n",
    "download_tarfile()\n",
    "extract_tarfile()\n",
    "build_and_save_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built the `Dataset`, let's look at what some of the ham and spam emails look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> HAM EMAIL:\n",
      "========================================================================\n",
      "Subject: mcmullen gas for 11 / 99\n",
      "jackie ,\n",
      "since the inlet to 3 river plant is shut in on 10 / 19 / 99 ( the last day of\n",
      "flow ) :\n",
      "at what meter is the mcmullen gas being diverted to ?\n",
      "at what meter is hpl buying the residue gas ? ( this is the gas from teco ,\n",
      "vastar , vintage , tejones , and swift )\n",
      "i still see active deals at meter 3405 in path manager for teco , vastar ,\n",
      "vintage , tejones , and swift\n",
      "i also see gas scheduled in pops at meter 3404 and 3405 .\n",
      "please advice . we need to resolve this as soon as possible so settlement\n",
      "can send out payments .\n",
      "thanks\n",
      "\n",
      ">>> SPAM EMAIL:\n",
      "========================================================================\n",
      "Subject: re : rdd , the auxiliary iturean\n",
      "free cable @ tv\n",
      "dabble bam servomechanism ferret canopy bookcase befog seductive elapse ballard daphne acrylate deride decadent desolate else sequestration condition ligament ornately yaqui giblet emphysematous woodland lie segovia almighty coffey shut china clubroom diagnostician\n",
      "cheer leadsman abominate cambric oligarchy mania woodyard quake tetrachloride contiguous welsh depressive synaptic trauma cloister banks canadian byroad alexander gnaw annette charlie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "\n",
    "print()\n",
    "print(\">>> HAM EMAIL:\")\n",
    "print(\"=\" * 72)\n",
    "print(DATASET.ham_emails[5].text_content())\n",
    "\n",
    "print()\n",
    "print(\">>> SPAM EMAIL:\")\n",
    "print(\"=\" * 72)\n",
    "print(DATASET.spam_emails[10].text_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the email text is all lower case, and each *token* (words, but also symbols like \"@\") is seperated by a space. The subject line is not technically part of the email body, but I will leave it in anyway.\n",
    "\n",
    "For the purposes of our algorithm, we will convert emails into a set of words, throwing away the order of the words, and also how frequently they occur in the email. Every token will be represented with an integer, rather than the word itself.\n",
    "\n",
    "We will represent whether an email is spam or not with a 1 for spam and a 0 for not spam. This is called the *label*.\n",
    "\n",
    "Below I look at the set of words and the set of codes for an email. I also look at its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SortedSet([',', ':', '@', 'Subject:', 'abominate', 'acrylate', 'alexander', 'almighty', 'annette', 'auxiliary', 'ballard', 'bam', 'banks', 'befog', 'bookcase', 'byroad', 'cable', 'cambric', 'canadian', 'canopy', 'charlie', 'cheer', 'china', 'cloister', 'clubroom', 'coffey', 'condition', 'contiguous', 'dabble', 'daphne', 'decadent', 'depressive', 'deride', 'desolate', 'diagnostician', 'elapse', 'else', 'emphysematous', 'ferret', 'free', 'giblet', 'gnaw', 'iturean', 'leadsman', 'lie', 'ligament', 'mania', 'oligarchy', 'ornately', 'quake', 'rdd', 're', 'seductive', 'segovia', 'sequestration', 'servomechanism', 'shut', 'synaptic', 'tetrachloride', 'the', 'trauma', 'tv', 'welsh', 'woodland', 'woodyard', 'yaqui'], key=None, load=1000)\n",
      "SortedSet([0, 7, 13, 27, 69, 209, 306, 679, 1076, 1466, 1492, 3200, 3498, 3880, 4518, 5332, 5673, 6040, 6075, 7845, 10796, 11378, 11981, 12835, 14532, 16407, 17924, 20486, 20487, 20488, 20489, 20490, 20491, 20492, 20493, 20494, 20495, 20496, 20497, 20498, 20499, 20500, 20501, 20502, 20503, 20504, 20505, 20506, 20507, 20508, 20509, 20510, 20511, 20512, 20513, 20514, 20515, 20516, 20517, 20518, 20519, 20520, 20521, 20522, 20523, 20524], key=None, load=1000)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "\n",
    "print(DATASET.spam_emails[10].words_set())\n",
    "print(DATASET.spam_emails[10].codes)\n",
    "print(DATASET.spam_emails[10].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the preprocessing of the dataset *featurization*. The machine learning algorithm will interact with the *featurized* emails (the set of numbers and the 0/1 label), rather than the raw emails themselves.\n",
    "\n",
    "It is not uncommon to throw away word order and word counts. This representation of text is called the *bag of words model*. Obviously a lot of information is lost with this representation. For some tasks like document retrieval based on keyword matching, the bag of words model can still be useful. For tasks like spam/not-spam bag of words performs well.\n",
    "\n",
    "For tasks which need deeper *semantic* understanding of a document (understanding what it means), we would want to use techniques which can exploit the information contained in the word ordering. Naive Bayes would not be appropriate for tasks like that.\n",
    "\n",
    "Luckily, Naive Bayes does very well for classifying emails as spam/not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Probabilities\n",
    "\n",
    "To detect which emails are spam and which aren't, we will use the observation that some words are more probable to appear in a spam email rather than in a non-spam email. Words that are more likely to occur in a spam email than they would in a non-spam email is an indicator of spaminess.\n",
    "\n",
    "Let's make this precise using probabilities.\n",
    "\n",
    "Consider the word \"offer.\" Offer probably occurs more commonly in spam emails than in non-spam emails. Let's write this in notation:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    ">\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "\\\\]\n",
    "\n",
    "Here $\\text{OFFER} = 1$ means \"the word 'offer' is in the email.\" To say \"the word 'offer' is *not* in the email,\" we would write $\\text{OFFER} = 0$.\n",
    "\n",
    "Likewise, $\\text{SPAM} = 1$ means \"the email is spam,\" versus $\\text{SPAM} = 0$ which means \"the email is not spam.\"\n",
    "\n",
    "The *probability* that a randomly sampled email is spam is written:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "If we have a very large dataset, this probability can be defined as\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1} = \\frac{\\text{# of emails that are spam}}{\\text{# of emails in the dataset}}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to predict how probable it is that an email is spam, *given* that it contains the word \"offer.\" That is, I want to calculate\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "\\text{# of emails that are spam and contain the word \"offer\"}\n",
    "}{\n",
    "\\text{# of emails that contain the word \"offer\"}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "We write this like so:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "\\\\]\n",
    "\n",
    "The symbol $\\condbar$ seperates the result we're asking about ($\\text{SPAM} = 1$) from the *condition* ($\\text{OFFER} = 1$). This is called a *conditional probability*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another way to write a probability like this:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "=\n",
    "\\frac{\n",
    "\\prob{\\text{SPAM} = 1}\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "\\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Let me prove it's true. Replace each probability by its definition:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\frac{\n",
    "        \\text{# of SPAM emails}\n",
    "    }{\n",
    "        \\text{# of total emails}\n",
    "    }\n",
    "    \\frac{\n",
    "        \\text{# of SPAM emails with the word OFFER}\n",
    "    }{\n",
    "        \\text{# of SPAM emails}\n",
    "    }\n",
    "}{\n",
    "    \\frac{\n",
    "        \\text{# of emails with the word OFFER}\n",
    "    }{\n",
    "        \\text{# of total emails}\n",
    "    }\n",
    "}\n",
    "&=\n",
    "\\frac{\n",
    "    \\frac{\n",
    "        \\text{# of SPAM emails with the word OFFER}\n",
    "    }{\n",
    "        \\text{# of total emails}\n",
    "    }\n",
    "}{\n",
    "    \\frac{\n",
    "        \\text{# of emails with the word OFFER}\n",
    "    }{\n",
    "        \\text{# of total emails}\n",
    "    }\n",
    "}\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\text{# of SPAM emails with the word OFFER}\n",
    "}{\n",
    "    \\text{# of emails with the word OFFER}\n",
    "}\n",
    "\\\\\n",
    "&=\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "This rule is called *Bayes' Rule*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can apply the same equation to $\\text{SPAM} = 0$. That gives me:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 0 \\condbar \\text{OFFER} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "It is frequently convenient to consider the *odds* that something is true, rather than the probability. If the probability of $X$ is $p$, then the *odds* of $X$ are $\\frac{p}{1-p}$. For instance, a probability of $0.66$ corresponds to an odds of $2$, sometimes written $2:1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the odds that an email is spam, given that it has the word \"offer\" in it.\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0 \\condbar \\text{OFFER} = 1}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "The first factor in the product is what I call the *base odds*. It is the odds of an email being spam if it is randomly sampled and we know nothing else about it.\n",
    "\n",
    "The second factor in the product I will call the *feature probability ratio*. It is the ratio of probabilities that the feature will occur conditional on $SPAM = 1$ versus when $SPAM = 0$.\n",
    "\n",
    "When this ratio is $>1$, the probability the word occurs in a spam email is higher than the probability it would occur in a non-spam email.\n",
    "\n",
    "When this ratio is $>1$, it means that if we know an email contains the word \"offer\", the odds are better that the email is spam. This is because the base odds are multiplied by a number greater than one.\n",
    "\n",
    "Likewise, if the feature probability ratio is $<1$, than if we know an email contains the word \"offer\", that makes it less like that the email is spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use code to calculate\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{W_i} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{W_i} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "For every word $W_i$ in our vocabulary. So we'll calculate the ratio for the word \"offer,\" and we'll calculate it for the word \"Enron\", and we'll calculate for the word \"baldness.\"\n",
    "\n",
    "The words with the highest ratio are those that are the greatest indicators of spam. Those words multiply the base odds by the greatest feature probability ratio, so that the conditional odds that an email is spam are greatest.\n",
    "\n",
    "Below code just counts up these numbers. It will count up how many times a word occurs in spam emails. It will divide by the number of spam emails. This is the value of the numerator.\n",
    "\n",
    "It does the same thing for the denominator: count the number of times the word occurs in non-spam emails. It divides by the number of non-spam emails.\n",
    "\n",
    "Last, it divides these two probabilities, which is the feature probability ratio defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Keeps track of how many time a word occurs in ham or spam emails.\n",
    "class Counts:\n",
    "    def __init__(self, ham_count = 0, spam_count = 0):\n",
    "        self.ham_count, self.spam_count = (\n",
    "            ham_count, spam_count\n",
    "        )\n",
    "\n",
    "    def total_count(self):\n",
    "        return self.ham_count + self.spam_count\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__dict__.__repr__()\n",
    "\n",
    "# Represents the unconditional class probabilities Pr(SPAM = 1), Pr(SPAM = 0)\n",
    "class PriorClassProbabilities:\n",
    "    def __init__(self, class_counts):\n",
    "        self.ham_prior_prob = (\n",
    "            class_counts.ham_count / class_counts.total_count()\n",
    "        )\n",
    "        self.spam_prior_prob = (\n",
    "            class_counts.spam_count / class_counts.total_count()\n",
    "        )\n",
    "\n",
    "# Calculates the feature probability ratio defined above.\n",
    "class ConditionalFeatureProbabilityRatio:\n",
    "    def __init__(self, feature_counts, class_counts):\n",
    "        self.prob_feature_given_ham = (\n",
    "            feature_counts.ham_count / class_counts.ham_count\n",
    "        )\n",
    "        self.prob_feature_given_spam = (\n",
    "            feature_counts.spam_count / class_counts.spam_count\n",
    "        )\n",
    "\n",
    "        if (self.prob_feature_given_ham != 0):\n",
    "            self.feature_probability_ratio = (\n",
    "                self.prob_feature_given_spam\n",
    "                / self.prob_feature_given_ham\n",
    "            )\n",
    "        else:\n",
    "            self.feature_probability_ratio = np.inf\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__dict__.__repr__()\n",
    "\n",
    "# Keeps a map of codes to feature probability ratio.\n",
    "class FeatureProbabilities:\n",
    "    def __init__(self):\n",
    "        self.class_counts = Counts()\n",
    "        self.code_counts = {}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_dataset(cls, dataset):\n",
    "        return cls.from_emails(\n",
    "            ham_emails = dataset.ham_emails,\n",
    "            spam_emails = dataset.spam_emails\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_emails(cls, ham_emails, spam_emails):\n",
    "        fps = cls()\n",
    "\n",
    "        for ham_email in ham_emails:\n",
    "            fps.add_email(ham_email, True)\n",
    "        for spam_email in spam_emails:\n",
    "            fps.add_email(spam_email, False)\n",
    "\n",
    "        return fps\n",
    "\n",
    "    def add_email(self, email, is_ham_email):\n",
    "        if is_ham_email:\n",
    "            self.class_counts.ham_count += 1\n",
    "        else:\n",
    "            self.class_counts.spam_count += 1\n",
    "\n",
    "        for code in email.codes:\n",
    "            self._check_code_added(code)\n",
    "\n",
    "            if is_ham_email:\n",
    "                self.code_counts[code].ham_count += 1\n",
    "            else:\n",
    "                self.code_counts[code].spam_count += 1\n",
    "\n",
    "    def class_prior_probs(self):\n",
    "        return PriorClassProbabilities(self.class_counts)\n",
    "\n",
    "    # Gives you Pr(W_i = 1 | SPAM = 1) / Pr(W_i = 1 | SPAM = 0)\n",
    "    def code_prob_ratio(self, code):\n",
    "        return ConditionalFeatureProbabilityRatio(\n",
    "            feature_counts = self.code_counts[code],\n",
    "            class_counts = self.class_counts\n",
    "        )\n",
    "\n",
    "    def no_code_counts(self, code):\n",
    "        code_counts = self.code_counts[code]\n",
    "        return Counts(\n",
    "            ham_count = (\n",
    "                self.class_counts.ham_count - code_counts.ham_count\n",
    "            ),\n",
    "            spam_count = (\n",
    "                self.class_counts.spam_count - code_counts.spam_count\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Gives you Pr(W_i = 0 | SPAM = 1) / Pr(W_i = 0 | SPAM = 0)\n",
    "    def no_code_prob_ratio(self, code):\n",
    "        return ConditionalFeatureProbabilityRatio(\n",
    "            feature_counts = self.no_code_counts(code),\n",
    "            class_counts = self.class_counts\n",
    "        )\n",
    "\n",
    "    def _check_code_added(self, code):\n",
    "        if code in self.code_counts: return\n",
    "        self.code_counts[code] = Counts(\n",
    "            ham_count = 0,\n",
    "            spam_count = 0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prob_feature_given_ham': 0.01661220043572985, 'prob_feature_given_spam': 0.094, 'feature_probability_ratio': 5.658491803278688}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "feature_probabilities = FeatureProbabilities.from_dataset(DATASET)\n",
    "feature_probabilities.code_prob_ratio(\n",
    "    code = DATASET.word_encoding_dictionary.word_to_code('offer')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1} = 0.094\n",
    "\\\\\n",
    "\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0} = 0.0166\n",
    "\\\\\n",
    "\\frac{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "= 5.66\n",
    "\\\\]\n",
    "\n",
    "Therefore, we can use our equation from above:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0 \\condbar \\text{OFFER} = 1}\n",
    "}\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "5.66\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "What we see here is that, whatever the base odds of a randomly selected email being spam, then if you know it contains the word \"offer\", the odds are now $5.66$ times greater that it is indeed spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Quantities Can Be Inaccurate\n",
    "\n",
    "To calculate the feature probability ratio, we are dividing two conditional probabilities: $\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}$ and $\\prob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 0}$.\n",
    "\n",
    "To calculate these probabilities, we're just using the emails we have in our dataset. We are just counting emails and dividing:\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{OFFER} = 1 \\condbar \\text{SPAM} = 1}\n",
    "=\n",
    "\\frac{\n",
    "\\text{# of emails that are spam and contain the word \"offer\"}\n",
    "}{\n",
    "\\text{# of emails that are spam}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "I have put a \"hat\" on the probability, because this is an *estimate* of the probability. A hat means estimate. It isn't necessarily the true probability we would get if we considered every email ever written. We are only look at a much smaller *sample* dateaset.\n",
    "\n",
    "For instance, let's say that \"xylophone\" never occurs in a spam email in our dataset. Then we calculate:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "&=\n",
    "\\frac{\n",
    "\\text{# of emails that are spam and contain the word \"xylophone\"}\n",
    "}{\n",
    "\\text{# of emails that are spam}\n",
    "}\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    0\n",
    "}{\n",
    "    \\text{# of emails that are spam}\n",
    "}\n",
    "\\\\\n",
    "&=\n",
    "0\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our calculation above is accurate, it means that no spam email will ever have the word \"offer\" in it. Now, that is true *in our dataset*, but is it true that no spam email *ever* contained the word \"xylophone?\" If so, then this probability is wrong. The probability is surely very small, but it can't be *exactly* zero.\n",
    "\n",
    "That said, surely \"xylophone\" is very rare in spam emails. Let's presume that it is equally rare in ham emails. In that case:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "=\n",
    "\\prob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 0}\n",
    "\\\\\n",
    "\\Rightarrow\n",
    "\\frac{\n",
    "    \\prob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "= 1.0\n",
    "\\\\]\n",
    "\n",
    "Notice I am not using hats here, because I'm talking about the *true* probabilities we would measure if we had every email ever written. If the true feature probabilities are equal, then the feature probability ratio should be one, which means that \"xylophone\" doesn't change the odds that an email is spam. That's what it means to be equally likely in spam and non-spam emails.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, let us say by random chance, even though \"xylophone\" never appears in our spam dataset, it occurs that \"xylophone\" does appear in one non-spam email. That is:\n",
    "\n",
    "\\\\[\n",
    "\\text{# of non-spam emails with the word \"xylophone\"} = 1\n",
    "\\\\\n",
    "\\text{# of spam emails with the word \"xylophone\"} = 0\n",
    "\\\\]\n",
    "\n",
    "If that is true, then:\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 0}\n",
    ">\n",
    "0\n",
    "\\\\\n",
    "\\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "=\n",
    "0\n",
    "\\\\]\n",
    "\n",
    "And that would mean:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    0\n",
    "}{\n",
    "    \\text{some number} > 0\n",
    "}\n",
    "=\n",
    "0\n",
    "\\\\]\n",
    "\n",
    "So this means that \n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\ne\n",
    "\\frac{\n",
    "    \\prob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Now, any *estimate* will always be a little inaccurate. But the problem here is that the estimate is *very* wrong about the odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say you want to predict if some future email is spam. Let's say this new email has the word xylophone. Then:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\eprob{\\text{SPAM} = 1 \\condbar \\text{XYLOPHONE} = 1}\n",
    "}{\n",
    "    \\eprob{\\text{SPAM} = 0 \\condbar \\text{XYLOPHONE} = 1}\n",
    "}\n",
    "&=\n",
    "\\frac{\n",
    "    \\eprob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\eprob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\eprob{\\text{XYLOPHONE} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\eprob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\eprob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "0\n",
    "\\\\\n",
    "&=\n",
    "0\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "That would mean that any future email that contains the word xylophone, we think there is a 0% chance that it is spam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what we're seeing:\n",
    "\n",
    "(1) If a word is very rare, our estimate of the feature probability ratio can be *very* wrong.\n",
    "\n",
    "(2) Therefore, if we use the feature probability ratio to calculate the conditional odds \n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\eprob{\\text{SPAM} = 1 \\condbar \\text{XYLOPHONE} = 1}\n",
    "}{\n",
    "    \\eprob{\\text{SPAM} = 0 \\condbar \\text{XYLOPHONE} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "then this estimate can be very wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I show an example with the word \"bacterial.\" This occurs once in a spam email, and never in a non-spam email. Therefore, we'll think that any new email with the word \"bacterial\" has a 100% chance of being spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts | {'ham_count': 0, 'spam_count': 1}\n",
      "Feature Probability Ratio | {'prob_feature_given_ham': 0.0, 'prob_feature_given_spam': 0.0006666666666666666, 'feature_probability_ratio': inf}\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "\n",
    "bacterial_code = DATASET.word_encoding_dictionary.word_to_code('bacterial')\n",
    "print(f\"Counts | {feature_probabilities.code_counts[bacterial_code]}\")\n",
    "print(f\"Feature Probability Ratio | {feature_probabilities.code_prob_ratio(bacterial_code)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than think that any email with the word \"bacterial\" is 100% for sure spam, maybe we should just *ignore* the word \"bacterial.\" Basically: we don't know enough about the word \"bacterial\" to know whether it really does indicate spam or ham. It is simply too rare a word for us to know without more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discarding Low Reach Features\n",
    "\n",
    "The code below goes through all the features, and it throws out any of those with low *reach*. That is: it throws out words which occur in less than one hundred emails. One hundred is chosen arbitrarily.\n",
    "\n",
    "The idea is: if a word $W$ occurs in about 100 emails, then we have enough occurences to fairly accurately estimate the true $\\prob{W = 1 \\condbar \\text{SPAM} = 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After throwing out these low reach words, I'll list all the words that are the best predictors of spam. That is: I'll show all the words $W$ where\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{W = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "is the greatest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A helper class to explore best ham/spam features.\n",
    "class FeatureProbabilitiesExplorer:\n",
    "    @classmethod\n",
    "    def best_spam_features(\n",
    "        cls, fps, limit = 20, present_features = True\n",
    "    ):\n",
    "        return cls.best_features(\n",
    "            fps, limit, -1, present_features = present_features\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def best_ham_features(\n",
    "        cls, fps, limit = 20, present_features = True\n",
    "    ):\n",
    "        return cls.best_features(\n",
    "            fps, limit, +1, present_features = present_features\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def best_features(cls, fps, limit, multiplier, present_features):\n",
    "        if present_features:\n",
    "            prob_ratio_fn = fps.code_prob_ratio\n",
    "            code_counts = lambda code: fps.code_counts[code]\n",
    "        else:\n",
    "            prob_ratio_fn = fps.no_code_prob_ratio\n",
    "            code_counts = fps.no_code_counts\n",
    "\n",
    "        codes = list(fps.code_counts.keys())\n",
    "        code_prob_ratios = [{\n",
    "            'code': code,\n",
    "            'reach': code_counts(code),\n",
    "            'feature_probability_ratio': (\n",
    "                prob_ratio_fn(code).feature_probability_ratio\n",
    "            )\n",
    "        } for code in codes]\n",
    "        code_prob_ratios.sort(key = lambda code_prob_ratio: (\n",
    "            multiplier * code_prob_ratio['feature_probability_ratio']\n",
    "        ))\n",
    "        return code_prob_ratios[:limit]\n",
    "\n",
    "    @classmethod\n",
    "    def print_features_list(\n",
    "        cls, features_list, word_encoding_dictionary\n",
    "    ):\n",
    "        for code_prob_ratio in features_list:\n",
    "            code, reach, feature_probability_ratio = (\n",
    "                code_prob_ratio['code'],\n",
    "                code_prob_ratio['reach'],\n",
    "                code_prob_ratio['feature_probability_ratio']\n",
    "            )\n",
    "            word = word_encoding_dictionary.code_to_word(code)\n",
    "            print(\n",
    "                f\"{code} | {word} | reach: {reach} | \"\n",
    "                f\"feature_probability_ratio: {feature_probability_ratio:0.2f}:1\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17077 | 2004 | reach: {'ham_count': 1, 'spam_count': 121} | feature_probability_ratio: 296.21:1\n",
      "5969 | microsoft | reach: {'ham_count': 11, 'spam_count': 98} | feature_probability_ratio: 21.81:1\n",
      "3104 | investment | reach: {'ham_count': 11, 'spam_count': 96} | feature_probability_ratio: 21.36:1\n",
      "3522 | results | reach: {'ham_count': 18, 'spam_count': 98} | feature_probability_ratio: 13.33:1\n",
      "370 | v | reach: {'ham_count': 26, 'spam_count': 134} | feature_probability_ratio: 12.62:1\n",
      "3951 | million | reach: {'ham_count': 20, 'spam_count': 97} | feature_probability_ratio: 11.87:1\n",
      "680 | stop | reach: {'ham_count': 31, 'spam_count': 147} | feature_probability_ratio: 11.61:1\n",
      "3900 | software | reach: {'ham_count': 22, 'spam_count': 101} | feature_probability_ratio: 11.24:1\n",
      "5621 | 80 | reach: {'ham_count': 23, 'spam_count': 104} | feature_probability_ratio: 11.07:1\n",
      "4002 | dollars | reach: {'ham_count': 26, 'spam_count': 113} | feature_probability_ratio: 10.64:1\n",
      "4611 | remove | reach: {'ham_count': 28, 'spam_count': 110} | feature_probability_ratio: 9.62:1\n",
      "3462 | stock | reach: {'ham_count': 22, 'spam_count': 84} | feature_probability_ratio: 9.35:1\n",
      "4795 | removed | reach: {'ham_count': 22, 'spam_count': 83} | feature_probability_ratio: 9.24:1\n",
      "2772 | money | reach: {'ham_count': 50, 'spam_count': 187} | feature_probability_ratio: 9.16:1\n",
      "2737 | world | reach: {'ham_count': 34, 'spam_count': 124} | feature_probability_ratio: 8.93:1\n",
      "2512 | save | reach: {'ham_count': 35, 'spam_count': 125} | feature_probability_ratio: 8.74:1\n",
      "2518 | http | reach: {'ham_count': 135, 'spam_count': 475} | feature_probability_ratio: 8.61:1\n",
      "570 | quality | reach: {'ham_count': 29, 'spam_count': 101} | feature_probability_ratio: 8.53:1\n",
      "4517 | canada | reach: {'ham_count': 23, 'spam_count': 79} | feature_probability_ratio: 8.41:1\n",
      "3347 | low | reach: {'ham_count': 31, 'spam_count': 106} | feature_probability_ratio: 8.37:1\n"
     ]
    }
   ],
   "source": [
    "def filter_feature_probabilities(fps, reach_limit):\n",
    "    filtered_fps = FeatureProbabilities()\n",
    "    filtered_fps.class_counts = Counts(\n",
    "        ham_count = fps.class_counts.ham_count,\n",
    "        spam_count = fps.class_counts.spam_count\n",
    "    )\n",
    "\n",
    "    for (code, counts) in fps.code_counts.items():\n",
    "        if counts.total_count() < reach_limit: continue\n",
    "        filtered_fps.code_counts[code] = Counts(\n",
    "            ham_count = counts.ham_count,\n",
    "            spam_count = counts.spam_count\n",
    "        )\n",
    "\n",
    "    return filtered_fps\n",
    "\n",
    "DATASET = Dataset.get()\n",
    "filtered_feature_probabilities = filter_feature_probabilities(\n",
    "    FeatureProbabilities.from_dataset(DATASET),\n",
    "    reach_limit = 100\n",
    ")\n",
    "best_spam_features = FeatureProbabilitiesExplorer.best_spam_features(\n",
    "    filtered_feature_probabilities\n",
    ")\n",
    "FeatureProbabilitiesExplorer.print_features_list(\n",
    "    best_spam_features, DATASET.word_encoding_dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list is pretty good! Most of the words intuitively fit with what we think might be in a spam email. \"2004\" is weird, but let's ignore that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all the words\n",
    "\n",
    "So far we have calculated probabilities like:\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1}\n",
    "\\\\]\n",
    "\n",
    "This tells us the probability that a randomly drawn email is spam, if we know it contains the word \"offer.\"\n",
    "\n",
    "What if you tell me the email contains *both* the words \"offer\" and \"limited?\" That probably makes it *more* likely to be spam, because \"limited\" is probably a spammy word too.\n",
    "\n",
    "I want to calculate:\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1 \\wedge \\text{LIMITED} = 1}\n",
    "\\\\]\n",
    "\n",
    "The wedge $\\wedge$ means \"AND.\"\n",
    "\n",
    "Eventually, I want to use *all* the words in an email. When I classify an email as ham or spam, I get to look at *all* the words.\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1 \\condbar \\text{all the words in the email}}\n",
    "\\\\]\n",
    "\n",
    "My expectation is that the more words I use, the better my guess about whether the email is spam. More words is more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with just two words. I want to calculate:\n",
    "\n",
    "\\\\[\n",
    "\\eprob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1 \\wedge \\text{LIMITED} = 1}\n",
    "\\\\]\n",
    "\n",
    "One problem I'll encounter is that, even if $>100$ emails have the word \"offer,\" and $>100$ emails have the word \"limited,\" it may not be true that $>100$ emails have *both* words. That would be bad, because:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\\eprob{\\text{SPAM} = 1 \\condbar \\text{OFFER} = 1 \\wedge \\text{LIMITED} = 1}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\text{# of emails with both the words offer and limited, AND is spam}\n",
    "}{\n",
    "    \\text{# of emails with both the words offer and limited}\n",
    "}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Again, if there are very few emails with both, this estimate can be very wrong. For instance, if the number of emails with both the words offer and limited is just one, then this estimated probability will be either 0% or 100%, which are the most extreme possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental problem is this. The more words you try to use from an email, the smaller the count of the denominator. That means our estimate is likely to be highly inaccurate.\n",
    "\n",
    "We need to come up with a trick to get around this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence\n",
    "\n",
    "Let's try to get around the problem. We'll start with using Bayes' Rule:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "We can write this as odds:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's make an *assumption*. Let's assume:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "=\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "Similarly, let's assume:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "=\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "\\\\]\n",
    "\n",
    "These assumptions are *not true*. Let's just pretend they are true, though. I'll discuss them more in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use these equalities hold, then we can substitute into the odds equation above:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0\\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "    \\cdot\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "    \\cdot\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that we now have an equation for the odds where no probability involves *both* \"investment\" and \"quality\". That's good, because if \"investment\" and \"quality\" are both individually high reach features, these estimated probabilities will be accurate, like we said before.\n",
    "\n",
    "So, *if our assumption is true*, we have found a good way to calculate the odds. It doesn't involve a probability about two words, which can be low reach, even if the individual features are high reach. This makes the odds calculation is much more accurate, *assuming our assumption is true.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Did We Assume?\n",
    "\n",
    "I already showed you how to break up a probability that involves a conjunction:\n",
    "\n",
    "\\\\[\n",
    "\\prob{X = x \\wedge Y = y} = \\prob{X = x} \\prob{Y = y \\condbar X = x}\n",
    "\\\\]\n",
    "\n",
    "This is always true. It is a law. I proved it above. For the same reason, this law is also true:\n",
    "\n",
    "\\\\[\n",
    "\\prob{X = x \\wedge Y = y \\condbar Z = z}\n",
    "=\n",
    "\\prob{X = x \\condbar Z = z}\n",
    "\\prob{Y = y \\condbar X = x \\wedge Z = z}\n",
    "\\\\]\n",
    "\n",
    "If you are skeptical, prove it for yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that rule, I know:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\n",
    "\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "&\\\\\n",
    "&=\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's return to what we assumed:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\n",
    "\\prob{\\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "So our assumption is the same as assuming:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Which is the same as assuming:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence\n",
    "\n",
    "The property we assumed is called *conditional independence*. Conditional independence means:\n",
    "\n",
    "\\\\[\n",
    "\\prob{X = x \\condbar Y = y \\wedge Z = z} = \\prob{X = x \\condbar Y = y}\n",
    "\\\\]\n",
    "\n",
    "In this case, we say that \"X is conditionally independent of Z, given Y\".\n",
    "\n",
    "Let's talk in terms of our example:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "This says: an spam email is no more or less likely to contain the word \"quality\", regardless of whether it contains the word investment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples When Unconditional Independence Is Violated\n",
    "\n",
    "I want to give you an intuition about conditional independence. Let's talk about the *unconditional* independence first.\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{INVESTMENT} = 1}\n",
    "\\ne\n",
    "\\prob{\\text{QUALITY} = 1}\n",
    "\\\\]\n",
    "\n",
    "Here's why this isn't true in general.\n",
    "\n",
    "1. The presence of the word \"investment\" suggests that the email is spam.\n",
    "2. If the email is spam, then it is more likely to contain the word \"quality\" than the average email.\n",
    "3. That means that the presence of the word \"investment\" makes the presence of the word \"quality\" more likely.\n",
    "4. In conclusion, the words \"investment\" and \"quality\" are not unconditionally independent.\n",
    "\n",
    "In fact, by that reasoning,\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{INVESTMENT} = 1}\n",
    ">\n",
    "\\prob{\\text{QUALITY} = 1}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reason for Conditional Independence\n",
    "\n",
    "I've said that \"investment\" indicates spam, and spam indicates \"quality\", so \"investment\" indicates \"quality.\"\n",
    "\n",
    "The reason this happens is entirely because \"investment\" tells me what kind of email this is. Let's say I start out knowing whether an email is spam. My question then is, if I learn the email contains the word \"investment\", will my belief in the probability that the word \"quality\" appears change?\n",
    "\n",
    "That is:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\stackrel{?}{=}\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "\\\\]\n",
    "\n",
    "My old argument doesn't apply anymore. Even though \"investment\" normally indicates an email is spam, in this case I started out knowing that the email was spam. So learning that \"investment\" is in the email doesn't add *anything* to my knowledge about whether the email is spam in this case: I already knew.\n",
    "\n",
    "In that case, \"investment\" doesn't change my belief in the probability of the word \"quality\" being present. Unless some other new reasoning applies, the equation above is true:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "\\\\]\n",
    "\n",
    "In that case, \"quality\" is conditionally independent of \"investment\" given that an email is spam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples When Conditional Independence Is Violated\n",
    "\n",
    "The question then becomes: does the presence of the word \"investment\" change the probability of \"quality\" appearing for *any other* reason?\n",
    "\n",
    "Now, it may be possible that the words \"quality\" and \"investment\" often appear in the same spam emails because \"investment\" frequently appears as part of the compound phrase \"a quality investment\".\n",
    "\n",
    "That is, \"investment\" may indicate \"quality\" for a reason that isn't merely through \"investment\" indicating an email is \"spam.\" It may be because *those words simply go together*.\n",
    "\n",
    "If that were true, then:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    ">\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "This is the kind of thing we're assuming *doesn't happen.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, considering another pair of words, it may be that \"baldness\" is less likely given the presence of the word \"investment\" in spam emails. That might be because a spam email either pitches an investment or a baldness cure, but not typically both.\n",
    "\n",
    "In that case, the presence of \"investment\" might *inhibit* \"baldness.\" Those words *don't* go together.\n",
    "\n",
    "If this is true:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "<\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "Again: we will assume that *does not happen.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Just Pretend\n",
    "\n",
    "We've seen that, independent of their effect at hinting at whether an email is spam, a word like \"investment\" may (1) indicate the presence of \"quality\" or (2) indicate the absence of \"baldness.\"\n",
    "\n",
    "We've said we're just going to assume that doesn't happen. We will assume:\n",
    "\n",
    "\\\\[\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\\\\\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1 \\wedge \\text{INVESTMENT} = 1}\n",
    "=\n",
    "\\prob{\\text{BALDNESS} = 1 \\condbar \\text{SPAM} = 1}\n",
    "\\\\]\n",
    "\n",
    "It is typically the case that pairs of features are *not* conditionally independent. So our assumption is typically wrong. What's incredible is that we'll see that the Naive Bayes model can still do a good job with this false assumption.\n",
    "\n",
    "This is what makes Naive Bayes *naive*. Remember why we did this in the first place: usin g the naive assumption, we can calculate the odds that an email is spam using all the words in an email, while still avoiding the problem that as we include more words, it is more rare for all those words to occur together.\n",
    "\n",
    "In sum: Naive Bayes lets us use all the features, in a way which avoids inaccurate probability estimates, except that we base our model on an untrue assumption about conditional independence. And everything turns out okay!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Naive Bayes Model\n",
    "\n",
    "Let's remember where we have gotten to. By assuming conditional independence, we now know:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0 \\condbar \\text{INVESTMENT} = 1 \\wedge \\text{QUALITY} = 1}\n",
    "}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{INVESTMENT} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{QUALITY} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, let's use *all* the words. Let's number the words. Let's say that $W_1$ means \"OFFER\", $W_2$ means \"LIMITED\", et cetera. Let's say there are $N$ words in the *vocabulary*.\n",
    "\n",
    "An email's bag of words contains a *subset* of those $N$ words. Let's say the email contains $k$ unique words. Let's say they are words number $i_1, i_2, \\ldots, i_k$. Each $i_j$ is a different index of a different word in the email.\n",
    "\n",
    "Let's use our Naive Bayes equation now to calculate the probability that a randomly sampled email with these words would be spam:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1 \\condbar W_{i_1} = 1, \\ldots, W_{i_k} = 1 }\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0 \\condbar W_{i_1} = 1, \\ldots, W_{i_k} = 1 }\n",
    "}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{\\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{W_{i_1} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_1} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdot\n",
    "\\frac{\n",
    "    \\prob{W_{i_2} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_2} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_{i_k} = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{i_k} = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how to calculate the odds that an email is spam. Take the base odds, and then just multiply by each feature probability ratio for each word in the email.\n",
    "\n",
    "Below I wrote some code to do this. Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayesModel:\n",
    "    def __init__(self, fps, use_negative_features):\n",
    "        self.fps = fps\n",
    "        self.use_negative_features = use_negative_features\n",
    "\n",
    "    def _base_spam_score(self):\n",
    "        return (\n",
    "            self.fps.class_prior_probs().spam_prior_prob\n",
    "            / self.fps.class_prior_probs().ham_prior_prob\n",
    "        )\n",
    "\n",
    "    # This calculates the prob_ratios once so that we don't need to\n",
    "    # repeat this relatively costly computation\n",
    "    def _build_feature_weights(self):\n",
    "        # Note that because of filtering, some entries will remain\n",
    "        # 1.0. That's fine.\n",
    "        positive_code_prob_ratios = np.ones(\n",
    "            max(self.fps.code_counts.keys()) + 1\n",
    "        )\n",
    "        negative_code_prob_ratios = np.ones(\n",
    "            len(positive_code_prob_ratios)\n",
    "        )\n",
    "\n",
    "        for code in self.fps.code_counts:\n",
    "            positive_code_prob_ratios[code] = (\n",
    "                self.fps.code_prob_ratio(code).feature_probability_ratio\n",
    "            )\n",
    "            negative_code_prob_ratios[code] = (\n",
    "                self.fps.no_code_prob_ratio(code).feature_probability_ratio\n",
    "            )\n",
    "\n",
    "        return (positive_code_prob_ratios, negative_code_prob_ratios)\n",
    "\n",
    "    def score_email(\n",
    "        self,\n",
    "        email,\n",
    "        base_spam_score,\n",
    "        positive_code_prob_ratios,\n",
    "        negative_code_prob_ratios\n",
    "    ):\n",
    "        spam_score = base_spam_score\n",
    "        for code in self.fps.code_counts.keys():\n",
    "            if code in email.codes:\n",
    "                spam_score *= positive_code_prob_ratios[code]\n",
    "            elif self.use_negative_features:\n",
    "                spam_score *= negative_code_prob_ratios[code]\n",
    "\n",
    "        return spam_score\n",
    "\n",
    "    def score_emails(self, emails):\n",
    "        base_spam_score = self._base_spam_score()\n",
    "        (positive_code_prob_ratios, negative_code_prob_ratios) = (\n",
    "            self._build_feature_weights()\n",
    "        )\n",
    "\n",
    "        return map(\n",
    "            lambda email: self.score_email(\n",
    "                email = email,\n",
    "                base_spam_score = base_spam_score,\n",
    "                positive_code_prob_ratios = positive_code_prob_ratios,\n",
    "                negative_code_prob_ratios = negative_code_prob_ratios,\n",
    "            ),\n",
    "            emails\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below will test out how good a job our Naive Bayes model does at predicting whether an email is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper class (see below)\n",
    "class RecallResult:\n",
    "    def __init__(self, score_cutoff, num_spams_identified, recall):\n",
    "        self.score_cutoff, self.num_spams_identified, self.recall = (\n",
    "            score_cutoff, num_spams_identified, recall\n",
    "        )\n",
    "\n",
    "# Determines what percentage of spam emails are detected if we can tolerate a given false positive rate.\n",
    "# Does this for multiple false positive rate limits.\n",
    "def recall_for_false_positive_rates(model, dataset, limits):\n",
    "    ham_scores = list(model.score_emails(dataset.ham_emails))\n",
    "    ham_scores.sort(key = lambda score: -score)\n",
    "    spam_scores = list(model.score_emails(dataset.spam_emails))\n",
    "\n",
    "    def calculate_result(limit):\n",
    "        score_cutoff = ham_scores[int(len(ham_scores) * limit)]\n",
    "        num_spams_identified = sum(\n",
    "            [1 if s > score_cutoff else 0 for s in spam_scores]\n",
    "        )\n",
    "        recall = (\n",
    "            num_spams_identified / len(dataset.spam_emails)\n",
    "        )\n",
    "\n",
    "        return RecallResult(\n",
    "            score_cutoff = score_cutoff,\n",
    "            num_spams_identified = num_spams_identified,\n",
    "            recall = recall,\n",
    "        )\n",
    "\n",
    "    return [\n",
    "        (limit, calculate_result(limit)) for limit in limits\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the code and see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate 0.001 | Recall 0.08\n",
      "False Positive Rate 0.010 | Recall 0.62\n",
      "False Positive Rate 0.020 | Recall 0.88\n",
      "False Positive Rate 0.040 | Recall 0.98\n",
      "False Positive Rate 0.080 | Recall 1.00\n",
      "False Positive Rate 0.160 | Recall 1.00\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    filter_feature_probabilities(\n",
    "        FeatureProbabilities.from_dataset(DATASET),\n",
    "        reach_limit = 100\n",
    "    ),\n",
    "    use_negative_features = False\n",
    ")\n",
    "\n",
    "FALSE_POSITIVE_RATES = [0.001, 0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "results = recall_for_false_positive_rates(\n",
    "    model,\n",
    "    DATASET,\n",
    "    FALSE_POSITIVE_RATES\n",
    ")\n",
    "\n",
    "for (false_positive_rate, result) in results:\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.3f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *false positive rate* is the percentage of ham emails that were marked as spam. *Recall* is the percentage of percentage of spam emails that were identified as spam. Recall is the same as the *true positive rate*. Obviously the ideal is to have a false positive rate of zero and a recall of one.\n",
    "\n",
    "These results are encouraging. It says that if we're okay with marking one in a hundred ham emails as spam, we'll catch 62% of the spam. And if we are okay with two in a hundred ham emails, we'll catch 88% of spam.\n",
    "\n",
    "This isn't quite good enough for real life systems, but it isn't that bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Absence (Sometimes) Matters Too!\n",
    "\n",
    "See that `use_negative_features = False`? Right now we've only been using words that were observed: words whose presence indicates spam or not spam.\n",
    "\n",
    "Another question is what about the *absence* of words? What if all spam emails contain a word? If it is absent, then we know this is a ham email. But our calculation isn't using that kind of information.\n",
    "\n",
    "The way we've written our equations, it's as if we know that some words are present, but *don't know* whether the other words are *absent*. So let's rewrite slightly. Assume that $w_i = 1$ when the word $W_i$ is present, and $w_i = 0$ otherwise. Then:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{W_1 = w_1, \\ldots, W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = w_1, \\ldots, W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{W_1 = 1 \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = 1 \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 1}\n",
    "}{\n",
    "    \\prob{W_{\\card{W}} = w_{\\card{W}} \\condbar \\text{SPAM} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Let's see if the use of these features can help our model predict spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate 0.001 | Recall 0.09\n",
      "False Positive Rate 0.010 | Recall 0.71\n",
      "False Positive Rate 0.020 | Recall 0.93\n",
      "False Positive Rate 0.040 | Recall 0.98\n",
      "False Positive Rate 0.080 | Recall 1.00\n",
      "False Positive Rate 0.160 | Recall 1.00\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    filter_feature_probabilities(\n",
    "        FeatureProbabilities.from_dataset(DATASET),\n",
    "        reach_limit = 100\n",
    "    ),\n",
    "    use_negative_features = True\n",
    ")\n",
    "\n",
    "FALSE_POSITIVE_RATES = [0.001, 0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "results = recall_for_false_positive_rates(\n",
    "    model,\n",
    "    DATASET,\n",
    "    FALSE_POSITIVE_RATES\n",
    ")\n",
    "\n",
    "for (false_positive_rate, result) in results:\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.3f} | Recall {result.recall:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to have made a fairly substantial improvement! Let's look at what the best word omission features were!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===BEST SPAM OMISSION FEATURES===\n",
      "0 | Subject: | reach: {'ham_count': 0, 'spam_count': 0} | feature_probability_ratio: inf:1\n",
      "9 | . | reach: {'ham_count': 131, 'spam_count': 253} | feature_probability_ratio: 4.73:1\n",
      "7 | , | reach: {'ham_count': 447, 'spam_count': 423} | feature_probability_ratio: 2.32:1\n",
      "42 | for | reach: {'ham_count': 893, 'spam_count': 678} | feature_probability_ratio: 1.86:1\n",
      "100 | enron | reach: {'ham_count': 2210, 'spam_count': 1500} | feature_probability_ratio: 1.66:1\n",
      "610 | 2000 | reach: {'ham_count': 2162, 'spam_count': 1460} | feature_probability_ratio: 1.65:1\n",
      "55 | / | reach: {'ham_count': 1270, 'spam_count': 836} | feature_probability_ratio: 1.61:1\n",
      "24 | on | reach: {'ham_count': 1554, 'spam_count': 978} | feature_probability_ratio: 1.54:1\n",
      "19 | - | reach: {'ham_count': 893, 'spam_count': 558} | feature_probability_ratio: 1.53:1\n",
      "70 | cc | reach: {'ham_count': 2393, 'spam_count': 1490} | feature_probability_ratio: 1.52:1\n",
      "73 | subject | reach: {'ham_count': 2275, 'spam_count': 1393} | feature_probability_ratio: 1.50:1\n",
      "163 | thanks | reach: {'ham_count': 2323, 'spam_count': 1417} | feature_probability_ratio: 1.49:1\n",
      "13 | the | reach: {'ham_count': 992, 'spam_count': 596} | feature_probability_ratio: 1.47:1\n",
      "313 | hpl | reach: {'ham_count': 2574, 'spam_count': 1500} | feature_probability_ratio: 1.43:1\n",
      "128 | gas | reach: {'ham_count': 2558, 'spam_count': 1478} | feature_probability_ratio: 1.41:1\n",
      "81 | i | reach: {'ham_count': 2029, 'spam_count': 1153} | feature_probability_ratio: 1.39:1\n",
      "63 | daren | reach: {'ham_count': 2642, 'spam_count': 1500} | feature_probability_ratio: 1.39:1\n",
      "74 | please | reach: {'ham_count': 2091, 'spam_count': 1186} | feature_probability_ratio: 1.39:1\n",
      "62 | am | reach: {'ham_count': 2521, 'spam_count': 1429} | feature_probability_ratio: 1.39:1\n",
      "240 | pm | reach: {'ham_count': 2660, 'spam_count': 1486} | feature_probability_ratio: 1.37:1\n",
      "===BEST HAM OMISSION FEATURES===\n",
      "538 | ! | reach: {'ham_count': 3182, 'spam_count': 735} | feature_probability_ratio: 0.57:1\n",
      "571 | your | reach: {'ham_count': 2902, 'spam_count': 748} | feature_probability_ratio: 0.63:1\n",
      "2518 | http | reach: {'ham_count': 3537, 'spam_count': 1025} | feature_probability_ratio: 0.71:1\n",
      "717 | here | reach: {'ham_count': 3369, 'spam_count': 1056} | feature_probability_ratio: 0.77:1\n",
      "286 | no | reach: {'ham_count': 3248, 'spam_count': 1020} | feature_probability_ratio: 0.77:1\n",
      "965 | more | reach: {'ham_count': 3424, 'spam_count': 1079} | feature_probability_ratio: 0.77:1\n",
      "46 | % | reach: {'ham_count': 3493, 'spam_count': 1125} | feature_probability_ratio: 0.79:1\n",
      "547 | our | reach: {'ham_count': 3106, 'spam_count': 1048} | feature_probability_ratio: 0.83:1\n",
      "557 | all | reach: {'ham_count': 3041, 'spam_count': 1029} | feature_probability_ratio: 0.83:1\n",
      "963 | com | reach: {'ham_count': 3070, 'spam_count': 1055} | feature_probability_ratio: 0.84:1\n",
      "2519 | www | reach: {'ham_count': 3563, 'spam_count': 1237} | feature_probability_ratio: 0.85:1\n",
      "149 | you | reach: {'ham_count': 1818, 'spam_count': 632} | feature_probability_ratio: 0.85:1\n",
      "875 | $ | reach: {'ham_count': 3263, 'spam_count': 1147} | feature_probability_ratio: 0.86:1\n",
      "600 | email | reach: {'ham_count': 3452, 'spam_count': 1216} | feature_probability_ratio: 0.86:1\n",
      "77 | get | reach: {'ham_count': 3180, 'spam_count': 1125} | feature_probability_ratio: 0.87:1\n",
      "530 | best | reach: {'ham_count': 3572, 'spam_count': 1272} | feature_probability_ratio: 0.87:1\n",
      "162 | ? | reach: {'ham_count': 2779, 'spam_count': 990} | feature_probability_ratio: 0.87:1\n",
      "655 | only | reach: {'ham_count': 3338, 'spam_count': 1194} | feature_probability_ratio: 0.88:1\n",
      "4355 | click | reach: {'ham_count': 3573, 'spam_count': 1288} | feature_probability_ratio: 0.88:1\n",
      "136 | s | reach: {'ham_count': 2727, 'spam_count': 986} | feature_probability_ratio: 0.89:1\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "\n",
    "filtered_feature_probabilities = filter_feature_probabilities(\n",
    "    FeatureProbabilities.from_dataset(DATASET),\n",
    "    reach_limit = 100\n",
    ")\n",
    "\n",
    "print(\"===BEST SPAM OMISSION FEATURES===\")\n",
    "best_spam_features = FeatureProbabilitiesExplorer.best_spam_features(\n",
    "    filtered_feature_probabilities,\n",
    "    present_features = False\n",
    ")\n",
    "FeatureProbabilitiesExplorer.print_features_list(\n",
    "    best_spam_features, DATASET.word_encoding_dictionary\n",
    ")\n",
    "\n",
    "print(\"===BEST HAM OMISSION FEATURES===\")\n",
    "best_ham_features = FeatureProbabilitiesExplorer.best_ham_features(\n",
    "    filtered_feature_probabilities,\n",
    "    present_features = False\n",
    ")\n",
    "FeatureProbabilitiesExplorer.print_features_list(\n",
    "    best_ham_features, DATASET.word_encoding_dictionary\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam emails seem to be more likely to lack punctuation. And it looks like spam emails tend not to mention Enron: this is clearly specific to our training dataset!\n",
    "\n",
    "It looks clear that emails that don't contain a link are more likely to be ham. That's presumably because spammers want you to go to their website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training And Test Sets\n",
    "\n",
    "The way we are measuring performance is a little too leniant. We are supposed to train a model that predicts whether future emails are ham/spam, but we're measuring performance on the *training set*. This is often problematic because sometimes models will just \"memorize\" the training dataset in a way that doesn't lead to any future good performance.\n",
    "\n",
    "For instance, say our model was able to record an exact map from a bag of words to a label of ham or spam. Then, since every email in the training set probably has a unique bag of words, the model would be able to just record an exact mapping of email to label. But when we go to evaluate new emails, new emails won't match any of those bags of words. Thus there would be no ability to predict labels for future emails.\n",
    "\n",
    "To make sure our model *generalizes* well, it is common to split our data into two parts: the *training set* and the *test set*. The training set is fed to the machine learning algorithm, and then we use the test set to measure performance of the learned model. Since the ML algorithm never has seen the test set before, this should be a fair test of its ability to detect spam.\n",
    "\n",
    "Let's train on 80% of the data, and leave 20% for testing. There is a conflict of interest when picking these proportions. The more data you train on, the better your model will be. But the more data in your testing set, the more accurate your estimate on how the model will generalize.\n",
    "\n",
    "When you have more data, you might use more less for testing, figuring this amount will still be sufficient. On the other hand, 80/20 is a pretty common ratio to use.\n",
    "\n",
    "There are fancy techniques like [cross-validation][0], but I won't talk about those here.\n",
    "\n",
    "[0]: https://en.wikipedia.org/wiki/Cross-validation_(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "class DatasetSplitter:\n",
    "    @classmethod\n",
    "    def split(cls, dataset, ratio):\n",
    "        datasetA = cls._split(dataset, ratio, 0)\n",
    "        datasetB = cls._split(dataset, ratio, 1)\n",
    "        return (datasetA, datasetB)\n",
    "\n",
    "    @classmethod\n",
    "    def _split(cls, dataset, ratio, mode):\n",
    "        split_ham_emails, split_spam_emails = [], []\n",
    "        emails_pairs = [\n",
    "            (dataset.ham_emails, split_ham_emails),\n",
    "            (dataset.spam_emails, split_spam_emails)\n",
    "        ]\n",
    "\n",
    "        for (emails, split_emails) in emails_pairs:\n",
    "            for email in emails:\n",
    "                # This is a fancy way to pseudorandomly but\n",
    "                # deterministically select emails. That way we always\n",
    "                # pick the same set of emails for reproducability\n",
    "                # across program runs.\n",
    "                h = zlib.crc32(email.path.encode())\n",
    "                p = h / (2**32 - 1)\n",
    "                if (mode == 0 and p < ratio) or (mode == 1 and p >= ratio):\n",
    "                    split_emails.append(email)\n",
    "\n",
    "        return Dataset(\n",
    "            dataset.word_encoding_dictionary,\n",
    "            ham_emails = split_ham_emails,\n",
    "            spam_emails = split_spam_emails\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_number of emails: 5172\n",
      "number of training emails: 4181\n",
      "number of test emails: 991\n",
      "False Positive Rate 0.001 | Recall 0.08\n",
      "False Positive Rate 0.010 | Recall 0.74\n",
      "False Positive Rate 0.020 | Recall 0.92\n",
      "False Positive Rate 0.040 | Recall 0.97\n",
      "False Positive Rate 0.080 | Recall 0.98\n",
      "False Positive Rate 0.160 | Recall 0.98\n"
     ]
    }
   ],
   "source": [
    "DATASET = Dataset.get()\n",
    "(training_set, test_set) = DatasetSplitter.split(DATASET, ratio = 0.80)\n",
    "\n",
    "print(f\"total_number of emails: {len(DATASET.ham_emails) + len(DATASET.spam_emails)}\")\n",
    "print(f\"number of training emails: {len(training_set.ham_emails) + len(training_set.spam_emails)}\")\n",
    "print(f\"number of test emails: {len(test_set.ham_emails) + len(test_set.spam_emails)}\")\n",
    "\n",
    "model = NaiveBayesModel(\n",
    "    filter_feature_probabilities(\n",
    "        FeatureProbabilities.from_dataset(training_set),\n",
    "        reach_limit = 100\n",
    "    ),\n",
    "    use_negative_features = True\n",
    ")\n",
    "\n",
    "FALSE_POSITIVE_RATES = [0.001, 0.01, 0.02, 0.04, 0.08, 0.16]\n",
    "results = recall_for_false_positive_rates(\n",
    "    model,\n",
    "    test_set,\n",
    "    FALSE_POSITIVE_RATES\n",
    ")\n",
    "\n",
    "for (false_positive_rate, result) in results:\n",
    "    print(f\"False Positive Rate {false_positive_rate:0.3f} | Recall {result.recall:0.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Generalizes Well\n",
    "\n",
    "As you can see, the naive bayes model has generalized very well to the test set. The recall numbers at each false positive rate are all mostly in line with the rates calculated over the entire dataset. That shows that we aren't just memorizing the training dataset.\n",
    "\n",
    "Overfitting is not normally a major problem for Naive Bayes models. This is because Naive Bayes is very simple. The way overfitting normally happens with other models is that parameters are carefully set so that if just the right set of features (those of the memorized example) come in, then the right answer goes out (the label of the memorized example).\n",
    "\n",
    "To do this, a model typically needs to coordinate many parameters so they are \"just right\" for the training example.\n",
    "\n",
    "However, the Naive Bayes model does no such coordination. It sets each parameter seperately. It has no way to tweak parameters so they have combined effects that are any different than their individual effects.\n",
    "\n",
    "Just because Naive Bayes is good at avoiding overfitting doesn't mean that it always gives high performance. It relies on this assumption that we *know* isn't true: that the presence of a word $w_i$ is independent of a word $w_j$ given the class of the example. In many contexts, understanding these interaction effects will be very important.\n",
    "\n",
    "For instance, if we want to classify emails based on *sentiment*, then words like \"good\", \"great\", \"awesome\" are positive signals, while \"terrible\", \"bad\", \"awful\" are negative signals. But what about \"This movie is not good?\" How is the Naive Bayes model supposed to know this is negative? It can't just make \"not\" a very negative word, because I could also say: \"This movie is not bad.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Versus Variance\n",
    "\n",
    "We will later explore a classic tradeoff of machine learning models: *bias* versus *variance*. We say a model class is very *biased* if it imposes a very simple, inflexible structure of model. For instance, a model class of linear models is much more biased than the model class of all polynomial functions.\n",
    "\n",
    "On the other hand, we say a model class has *high* variance if we learn very different models depending on what data we feed it. For instance: if I feed the first, third, et cetera emails into the Naive Bayes model, I will get mostly the same model as feeding in the second, fourth, et cetera emails. We say Naive Bayes has *low* variance. The idea is that the Naive Bayes model doesn't vary much in what sample you feed it.\n",
    "\n",
    "Models that exhibit high variance do so because they have more *capacity*. That means: they can capture more complex relationships. This additional flexibility often allows the model to capture relationships that \"aren't really there.\"\n",
    "\n",
    "We saw an example of this before with fitting the line to the Gaussian noise. A relationship like this is called *spurious*. Luckily, a linear model is very biased (has low capacity), so the spurious relationship the linear model thinks it found in the noise is very weak.\n",
    "\n",
    "The ability to capture spurious relationships often means that a model *thinks* it is doing a good job on the training dataset, but when we test it on the test dataset, the model fails badly. This happens because the things it thought it learned turn out to be false.\n",
    "\n",
    "All else equal, you want to minimize bias in your model class. Bias is basically simplifying assumptions about what kind of model explains the data. But those assumptions are typically not quite correct, and so your model may not perform well if your assumptions are too simplistic.\n",
    "\n",
    "On the other hand, when you have small amounts of data, you will prefer models with less capacity, because training a high capacity model with small amounts of data leads to high variance in outcome. Basically: there isn't enough data to convince the model not to use its additional capacity to model noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
