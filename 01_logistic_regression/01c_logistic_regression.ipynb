{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "From the previous notebook, I said that we want to try to find a better model than Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Run this cell to define useful Latex macros)**\n",
    "\\\\[\n",
    "\\newcommand{\\card}[1]{\\left\\lvert#1\\right\\rvert}\n",
    "\\newcommand{\\condbar}[0]{\\,\\big|\\,}\n",
    "\\newcommand{\\eprob}[1]{\\widehat{\\text{Pr}}\\left[#1\\right]}\n",
    "\\newcommand{\\fpartial}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lvert\\left\\lvert#1\\right\\rvert\\right\\rvert}\n",
    "\\newcommand{\\prob}[1]{\\text{Pr}\\left[#1\\right]}\n",
    "\\newcommand{\\pprob}[2]{\\text{Pr}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equations From Last Time\n",
    "\n",
    "Here is our Naive Bayes model equation:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{W_1 = w_1 \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = w_1 \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_M = w_M \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_M = w_M \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "And we saw we could rewrite this as:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\phi_0\n",
    "\\prod_{i = 1}^M\n",
    "\\phi_i^{w_i}\n",
    "\\phi_i^{\\prime 1 - w_i}\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Finally, we saw that we could then write:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\prob{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "&=\n",
    "\\frac{\n",
    "    \\phi_0\n",
    "    \\prod_{i = 1}^M\n",
    "    \\phi_i^{w_i}\n",
    "    \\phi_i^{\\prime 1 - w_i}\n",
    "}{\n",
    "    1\n",
    "    +\n",
    "    \\left(\n",
    "        \\phi_0\n",
    "        \\prod_{i = 1}^M\n",
    "        \\phi_i^{w_i}\n",
    "        \\phi_i^{\\prime 1 - w_i}\n",
    "    \\right)\n",
    "}\n",
    "\\\\\n",
    "\\prob{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "&=\n",
    "\\frac{\n",
    "    1\n",
    "}{\n",
    "    1\n",
    "    +\n",
    "    \\left(\n",
    "        \\phi_0\n",
    "        \\prod_{i = 1}^M\n",
    "        \\phi_i^{w_i}\n",
    "        \\phi_i^{\\prime 1 - w_i}\n",
    "    \\right)\n",
    "}\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximizing Likelihood\n",
    "\n",
    "From the last notebook, we saw that we want to maximize:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\pprob{\\phi}{\\mathcal{D}}\n",
    "&=\n",
    "\\prod_i^N\n",
    "\\pprob{\\phi}{\\text{S} = s_i \\condbar W_1 = w_{i, 1}, \\ldots, W_M = w_{i, M}}\n",
    "\\\\\n",
    "&=\n",
    "\\prod_i^N\n",
    "\\left(\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_{i, 1}, \\ldots, W_M = w_{i, M}}\n",
    "\\right)^{s_i}\n",
    "\\left(\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_{i, 1}, \\ldots, W_M = w_{i, M}}\n",
    "\\right)^{1 - s_i}\n",
    "\\\\\n",
    "&=\n",
    "\\prod_i^N\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\phi_0\n",
    "        \\prod_{j = 1}^M\n",
    "        \\phi_j^{w_{i, j}}\n",
    "        \\phi_j^{\\prime 1 - w_{i, j}}\n",
    "    }{\n",
    "        1\n",
    "        +\n",
    "        \\left(\n",
    "            \\phi_0\n",
    "            \\prod_{j = 1}^M\n",
    "            \\phi_j^{w_{i, j}}\n",
    "            \\phi_j^{\\prime 1 - w_{i, j}}\n",
    "        \\right)\n",
    "    }\n",
    "\\right)^{s_i}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        1\n",
    "    }{\n",
    "        1\n",
    "        +\n",
    "        \\left(\n",
    "            \\phi_0\n",
    "            \\prod_{j = 1}^M\n",
    "            \\phi_j^{w_{i, j}}\n",
    "            \\phi_j^{\\prime 1 - w_{i, j}}\n",
    "        \\right)\n",
    "    }\n",
    "\\right)^{1 - s_i}\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "I've written the $\\phi$ as a subscript of $\\Pr$ to try to emphasize that the \"probability\" is what our model thinks, and it depends on our choice of $\\phi$. Our job is going to be pick the $\\phi$ that maximizes this probability of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products Are Hard To Optimize\n",
    "\n",
    "Right now, we could turn Gradient *Ascent* loose on the likelihood function above and try to calculate the $\\phi$ that do the best job. In theory that should work, but Gradient Ascent will do a bad job.\n",
    "\n",
    "Here is why. Gradient Ascent/Descent is all about making many *small* changes to the parameters, each time trying to improve just a little bit. It's like trying to tune in to a radio station with a dial: you want to slowly turn the knob to find the right frequency. You don't want to rapidly turn the knob because you'll go way past the station you're trying to tune.\n",
    "\n",
    "So let's try to choose a small \"step size.\" Does $\\epsilon = 0.01$ sound pretty small?\n",
    "\n",
    "Well, let's go back and think about the odds for a single training example. That is:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\phi_0\n",
    "\\prod_{i = 1}^M\n",
    "\\phi_i^{w_i}\n",
    "\\phi_i^{\\prime 1 - w_i}\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Say you propose to change $\\phi_0$ by $\\epsilon$. Is this a small change? Well, it depends on what $\\phi_0$ is! If $\\phi_0$ is very large, then changing $\\epsilon$ won't have a very great percentage change to the odds. On the other hand, if $\\phi_0$ is small, then a change of $\\epsilon$ will have a *huge* change on the odds. For instance, if $\\phi_0 = \\epsilon$, then adding $\\epsilon$ to $\\phi_0$ will *double* the odds! The effect can be even greater when $\\phi_0$ is smaller!\n",
    "\n",
    "In general, a change of $\\epsilon$ to a $\\phi_i$ causes a percentage change in the odds equal to $\\frac{\\epsilon}{\\phi_i}$. This can be very great whenever $\\phi_i$ is small.\n",
    "\n",
    "Basically, there is no such thing as a \"small\" step, beacuse the size of a step is relative to the magnitude of the $\\phi_i$ are being changed.\n",
    "\n",
    "The problem is that specifically that a small step can cause a big percentage change in a parameter $\\phi_i$. That was also the case with linear regression. The problem is that it causes a big change in the overall result: the product: the odds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sums Are Easier To Optimize\n",
    "\n",
    "This doesn't really happen with sums. Consider a weighted sum:\n",
    "\n",
    "\\\\[\n",
    "y = w_0 + \\sum w_i x_i\n",
    "\\\\]\n",
    "\n",
    "If we change $w_i$ by $\\epsilon$, how much will $y$ change? It will change by $\\epsilon * x_i$. The percentage change is therefore: $\\frac{\\epsilon x_i}{w_0 + \\sum w_i x_i}$.\n",
    "\n",
    "In order for a change of $\\epsilon$ to have a huge percentage change, it would have to be that $w_0 + \\sum w_i x_i$ is very small. That is much less likely than just the one $w_i$ value being small.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn A Product Into A Sum\n",
    "\n",
    "Since sums are easy to optimize using Gradient Ascent/Descent, and products are hard, the natural choice is to turn a product into a sum! The way to do this is to use the logarithm function.\n",
    "\n",
    "Let's start with the initial odds function. Let's turn that into a *log odds* function. Since the odds was a product, the log odds will be a sum.\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&=\n",
    "\\phi_0\n",
    "\\prod_{i = 1}^{M}\n",
    "\\phi_i^{w_i}\n",
    "\\phi_i^{\\prime 1 - w_i}\n",
    "\\\\\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&=\n",
    "\\log\\left(\n",
    "    \\phi_0\n",
    "    \\prod_{i = 1}^{M}\n",
    "    \\phi_i^{w_i}\n",
    "    \\phi_i^{\\prime 1 - w_i}\n",
    "\\right)\n",
    "\\\\\n",
    "&=\n",
    "\\log\\phi_0\n",
    "+\n",
    "\\sum_{i = 1}^M\n",
    "    w_i \\log\\phi_i\n",
    "    +\n",
    "    (1 - w_i) \\log\\phi_i^\\prime\n",
    "\\\\\n",
    "&=\n",
    "\\left(\n",
    "    \\log\\phi_0 + \\sum_{i = 1}^M \\log\\phi_i^\\prime\n",
    "\\right)\n",
    "+\n",
    "\\sum_{i = 1}^M\n",
    "    w_i (\\log\\phi_i - \\log\\phi_i^\\prime)\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I could try to pick the $\\phi$ values that maximize this equation for the log probability. However, that would be kind of annoying, because the equation is more complex than it needs to be.\n",
    "\n",
    "Instead, I will *reparameterize* the equation. Instead of trying to find the best $\\phi$ values, let me try to find the best $\\theta$ values for the equation below:\n",
    "\n",
    "\n",
    "\\\\[\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\theta_0\n",
    "+ \\sum_{i=1}^M w_i \\theta_i\n",
    "\\\\]\n",
    "\n",
    "This really doesn't change anything. Instead of trying to find the best model in terms of $\\phi$, I will look for it in terms of $\\theta$. It's like the difference between measuring a distance in meters or feet: it doesn't really matter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Reparameterized Problem\n",
    "\n",
    "We now have an equation for the log odds in terms of $\\theta$. It is easy to get an equation for the odds by just exponentiating both sides:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\exp\\left(\n",
    "    \\theta_0\n",
    "    + \\sum_{i=1}^M w_i \\theta_i\n",
    "\\right)\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reflect on what we have accomplished through reparameterization. Now, if we propose to increase $\\theta_i$ by $\\epsilon$, this will scale the odds by a factor of $e^\\epsilon$, regardless of what $\\theta_i$ is. That means a change of $\\epsilon$ always has a consistent effect. We can now choose $\\epsilon$ to be small enough that the change in odds will always be very minor each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, we know how to calculate the probabilities from the odds:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "&=\n",
    "\\frac{\n",
    "    \\exp\\left(\n",
    "        \\theta_0\n",
    "        + \\sum_{i=1}^M w_i \\theta_i\n",
    "    \\right)\n",
    "}{\n",
    "    1\n",
    "    +\n",
    "    \\exp\\left(\n",
    "        \\theta_0\n",
    "        + \\sum_{i=1}^M w_i \\theta_i\n",
    "    \\right)\n",
    "}\n",
    "\\\\\n",
    "\\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "&=\n",
    "\\frac{\n",
    "    1\n",
    "}{\n",
    "    1\n",
    "    +\n",
    "    \\exp\\left(\n",
    "        \\theta_0\n",
    "        + \\sum_{i=1}^M w_i \\theta_i\n",
    "    \\right)\n",
    "}\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\sigma(z) = \\frac{e^z}{1 + e^z}$ is called the *logistic function*. It is the function that converts a log odds into a probability, which is exactly what we've done here.\n",
    "\n",
    "That where the name *logistic regression* comes from!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plug this into our likelihood equation above!\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\pprob{\\theta}{\\mathcal{D}}\n",
    "&=\n",
    "\\prod_i^N\n",
    "\\left(\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_{i, 1}, \\ldots, W_M = w_{i, M}}\n",
    "\\right)^{s_i}\n",
    "\\left(\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_{i, 1}, \\ldots, W_M = w_{i, M}}\n",
    "\\right)^{1 - s_i}\n",
    "\\\\\n",
    "&=\n",
    "\\prod_i^N\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\exp\\left(\n",
    "            \\theta_0\n",
    "            + \\sum_{j=1}^M w_{i, j} \\theta_j\n",
    "        \\right)\n",
    "    }{\n",
    "        1\n",
    "        +\n",
    "        \\exp\\left(\n",
    "            \\theta_0\n",
    "            + \\sum_{j=1}^M w_{i, j} \\theta_j\n",
    "        \\right)\n",
    "    }\n",
    "\\right)^{s_i}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        1\n",
    "    }{\n",
    "        1\n",
    "        +\n",
    "        \\exp\\left(\n",
    "            \\theta_0\n",
    "            + \\sum_{j=1}^M w_{i, j} \\theta_j\n",
    "        \\right)\n",
    "    }\n",
    "\\right)^{1 - s_i}\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! We're back to something we can optimize! But now, we will optimize it in terms of $\\theta$. This is easier, for the reasons stated above.\n",
    "\n",
    "We haven't changed anything. We've just reparameterized our problem in a way such that Gradient Ascent can work better!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Log Likelihood Instead Likelihood\n",
    "\n",
    "Remember that Gradient Ascent/Descent doesn't just try to change parameters by a fixed \"step size\" of $\\epsilon$. That's not exactly how it works.\n",
    "\n",
    "Instead, it tries to change a parameter $\\theta_i$ by $\\lambda \\fpartial{\\pprob{\\theta}{\\mathcal{D}}}{\\theta_i}$, where $\\lambda$ is the learning rate. That is, it wants to change parameters *more* if they have a bigger impact on $\\pprob{\\theta}{\\mathcal{D}}$, and *less* if they have a smaller impact on $\\pprob{\\theta}{\\mathcal{D}}$.\n",
    "\n",
    "The idea is this: it's more efficient to try to focus on changes that are giving you the biggest bang for your buck.\n",
    "\n",
    "This only really works if a change $\\epsilon$ in the optimized function has a consistent value. For instance, if we want to change $\\theta_1$ twice as much as $\\theta_2$ beacuse $\\fpartial{f_\\theta}{\\theta_1} = 2\\fpartial{f_\\theta}{\\theta_2}$, that only makes sense if a change in $f_\\theta$ of two units is twice as good as a change of one unit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't true with probabilities. Think in terms of odds. If a probability $p = 0.01$ then adding $\\epsilon = 0.01$ more than *doubles* the odds, because:\n",
    "\n",
    "\\\\[\n",
    "\\frac{0.01}{0.99} \\Rightarrow \\frac{0.02}{0.98}\n",
    "\\\\]\n",
    "\n",
    "That is *very* different from the effect if we change $p = 0.50$ by an $\\epsilon = 0.01$:\n",
    "\n",
    "\\\\[\n",
    "\\frac{0.50}{0.50} \\Rightarrow \\frac{0.51}{0.49}\n",
    "\\\\]\n",
    "\n",
    "In this case, the odds change by only 4%.\n",
    "\n",
    "So it is clear that the same change $\\epsilon$ can have very different changes in the odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, even a change of $\\epsilon$ in the odds can mean very different things. Consider if the odds double or half: those are symmetric changes, right?\n",
    "\n",
    "However, doubling the odds is a 100% change in the odds, whereas halving the odds is a 50% change.\n",
    "\n",
    "So optimizing the odds would suffer a similar problem as optimizing the probability. The size of a change is not consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing By Optimizing Log Likelihood\n",
    "\n",
    "**TODO**..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
