{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classification\n",
    "\n",
    "From the previous notebook, I said that we want to try to find a better model than Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Run this cell to define useful Latex macros)**\n",
    "\\\\[\n",
    "\\newcommand{\\card}[1]{\\left\\lvert#1\\right\\rvert}\n",
    "\\newcommand{\\condbar}[0]{\\,\\big|\\,}\n",
    "\\newcommand{\\eprob}[1]{\\widehat{\\text{Pr}}\\left[#1\\right]}\n",
    "\\newcommand{\\norm}[1]{\\left\\lvert\\left\\lvert#1\\right\\rvert\\right\\rvert}\n",
    "\\newcommand{\\prob}[1]{\\text{Pr}\\left[#1\\right]}\n",
    "\\newcommand{\\pprob}[2]{\\text{Pr}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our Naive Bayes model equation:\n",
    "\n",
    "\\\\[\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{W_1 = w_1 \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = w_1 \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_M = w_M \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_M = w_M \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "I want to rewrite this using the $\\phi$ variables I defined earlier:\n",
    "\n",
    "\\\\[\n",
    "\\phi_i\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{W_i = 1 \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_i = 1 \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\\\\n",
    "\\phi'_i\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{W_i = 0 \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_i = 0 \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\\\\n",
    "\\phi_0\n",
    "=\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0}\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "To do that, I'm going to use a little trick:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0}\n",
    "}\n",
    "\\frac{\n",
    "    \\prob{W_1 = w_1 \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_1 = w_1 \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\cdots\n",
    "\\frac{\n",
    "    \\prob{W_M = w_M \\condbar \\text{S} = 1}\n",
    "}{\n",
    "    \\prob{W_M = w_M \\condbar \\text{S} = 0}\n",
    "}\n",
    "\\\\\n",
    "&=\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0}\n",
    "}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\prob{W_1 = 1 \\condbar \\text{S} = 1}\n",
    "    }{\n",
    "        \\prob{W_1 = 1 \\condbar \\text{S} = 0}\n",
    "    }\n",
    "\\right)^{w_1}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\prob{W_1 = 0 \\condbar \\text{S} = 1}\n",
    "    }{\n",
    "        \\prob{W_1 = 0 \\condbar \\text{S} = 0}\n",
    "    }\n",
    "\\right)^{1 - w_1}\n",
    "\\\\\n",
    "&\\quad\n",
    "\\cdots\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\prob{W_M = 1 \\condbar \\text{S} = 1}\n",
    "    }{\n",
    "        \\prob{W_M = 1 \\condbar \\text{S} = 0}\n",
    "    }\n",
    "\\right)^{w_M}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\prob{W_M = 0 \\condbar \\text{S} = 1}\n",
    "    }{\n",
    "        \\prob{W_M = 0 \\condbar \\text{S} = 0}\n",
    "    }\n",
    "\\right)^{1 - w_M}\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "See the trick I did? For each word, there are now a *pair* of factors. One is the feature probability ratio for if the word is present, and the other is for when the word is absent. Because of the expontents, if $w_i = 1$, we'll raise the presence factor to the first power (stays the same), and raise the absence feature to the zeroth power (becomes one).\n",
    "\n",
    "The reason I use this trick is because it lets me get the $w_i$ *outside* the probabilities. In particular, it lets me write:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\prob{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\prob{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\phi_0\n",
    "\\phi_1^{w_1}\n",
    "\\phi_1^{\\prime 1 - w_1}\n",
    "\\cdots\n",
    "\\phi_M^{w_M}\n",
    "\\phi_M^{\\prime 1 - w_M}\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding A Better $\\phi$\n",
    "\n",
    "The equation above tells me how to compute the odds assuming that the words are conditionally independent given the email's class (spam or not spam).\n",
    "\n",
    "I want to explore other possible settings of $\\phi$. I want to try to find a better choice. From here on out, we should not assume that $\\phi$ is set like Naive Bayes says.\n",
    "\n",
    "To make clear that the odds I calculate will depend on the $\\phi$ I choose, I will write:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\phi_0\n",
    "\\phi_1^{w_1}\n",
    "\\phi_1^{\\prime 1 - w_1}\n",
    "\\cdots\n",
    "\\phi_M^{w_M}\n",
    "\\phi_M^{\\prime 1 - w_M}\n",
    "=\n",
    "\\phi_0\n",
    "\\prod_{i = 1}^{M}\n",
    "\\phi_i^{w_i}\n",
    "\\phi_i^{\\prime 1 - w_i}\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "The $\\phi$ is a subscript of $\\Pr$ to show that that calculated probability depends on our choice of $\\phi$.\n",
    "\n",
    "We have an equation to compute the odds. But we know that we could turn this into a probability pretty easily:\n",
    "\n",
    "\\\\[\n",
    "\\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "=\n",
    "\\frac{\n",
    "    \\phi_0\n",
    "    \\prod_{i = 1}^{M}\n",
    "    \\phi_i^{w_i}\n",
    "    \\phi_i^{\\prime 1 - w_i}\n",
    "}{\n",
    "    1 + \\left(\n",
    "        \\phi_0\n",
    "        \\prod_{i = 1}^{M}\n",
    "        \\phi_i^{w_i}\n",
    "        \\phi_i^{\\prime 1 - w_i}\n",
    "    \\right)\n",
    "}\n",
    "\\\\\n",
    "\\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "=\n",
    "\\frac{\n",
    "    1\n",
    "}{\n",
    "    1 + \\left(\n",
    "        \\phi_0\n",
    "        \\prod_{i = 1}^{M}\n",
    "        \\phi_i^{w_i}\n",
    "        \\phi_i^{\\prime 1 - w_i}\n",
    "    \\right)\n",
    "}\n",
    "\\\\]\n",
    "\n",
    "Great! Now we have equation for the probability that an email is spam (or not spam) given the words that appear in the email.\n",
    "\n",
    "Remember our criteria for choosing the best $\\phi$. We want to maximize the likelihood of the dataset. The likelihood is:\n",
    "\n",
    "\\\\[\n",
    "\\pprob{\\phi}{\\mathcal{D}}\n",
    "=\n",
    "\\prod_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\pprob{\\phi}{\\text{S} = s_i \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\\\]\n",
    "\n",
    "I'm going to use the same trick as before:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\pprob{\\phi}{\\mathcal{D}}\n",
    "&=\n",
    "\\prod_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\left(\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\right)^{s_i}\n",
    "\\left(\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\right)^{1 - s_i}\n",
    "\\\\\n",
    "&=\n",
    "\\prod_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\phi_0\n",
    "        \\prod_{i = 1}^{M}\n",
    "        \\phi_i^{w_i}\n",
    "        \\phi_i^{\\prime 1 - w_i}\n",
    "    }{\n",
    "        1 + \\left(\n",
    "            \\phi_0\n",
    "            \\prod_{i = 1}^{M}\n",
    "            \\phi_i^{w_i}\n",
    "            \\phi_i^{\\prime 1 - w_i}\n",
    "        \\right)\n",
    "    }\n",
    "\\right)^{s_i}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        1\n",
    "    }{\n",
    "        1 + \\left(\n",
    "            \\phi_0\n",
    "            \\prod_{i = 1}^{M}\n",
    "            \\phi_i^{w_i}\n",
    "            \\phi_i^{\\prime 1 - w_i}\n",
    "        \\right)\n",
    "    }\n",
    "\\right)^{1 - s_i}\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "Here we are! This is the formula that I want to *maximize*. It's the formula I want to choose the $\\phi$ values so that it is the greatest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products Are Hard To Optimize\n",
    "\n",
    "Right now, we could turn Gradient *Ascent* loose on the likelihood function above and try to calculate the $\\phi$ that do the best job. In theory that should work, but Gradient Ascent will do a bad job.\n",
    "\n",
    "Here is why. Consider a sum of numbers: $\\sum_i n_i$. Say I decide to tweak the number $n_1$ by decreasing its value by $\\epsilon$. How much does that change the sum? It changes it by $\\epsilon$, no matter what the numbers are. Therefore, I can choose $\\epsilon$ to be small, and know that small changes to the $n_i$ values will produce small changes in the sum.\n",
    "\n",
    "On the other hand, consider a product: $\\prod_i n_i$. Say I decide to tweak $n_1$ by decreasing its value by $\\epsilon$. How does that change the product?\n",
    "\n",
    "It can be much more extreme. It depends on $\\left|\\frac{\\epsilon}{n_1}\\right|$. If that is small, then the change to $n_1$ will have a small percentage change on the overall product.\n",
    "\n",
    "However, if $\\left|\\frac{\\epsilon}{n_1}\\right|$ is large, then the percentage change to the product will be very great. And here is the problem: no $\\epsilon$ value can be considered truly \"small,\" because it's entirely relative to the size of $n_1$. $\\epsilon$ can be small, but if $n_1$ is smaller still, then this is actually a *relatively* large value of $\\epsilon$.\n",
    "\n",
    "An $\\epsilon$ that is huge for $n_1$ might actually be very small for $n_2$. So there is no consistent notion of what is a \"small step.\"\n",
    "\n",
    "Gradient Ascent (and Descent) rely on making small changes to the parameters $\\phi_0, \\phi_i, \\phi^\\prime_i$. But I'm telling you that for a product, there is no consistent definition of a small step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn A Product Into A Sum\n",
    "\n",
    "Since sums are easy to optimize using Gradient Ascent/Descent, and products are hard, the natural choice is to turn a product into a sum! The way to do this is to use the logarithm function.\n",
    "\n",
    "Let's start with the initial odds function. Let's turn that into a *log odds* function. Since the odds was a product, the log odds will be a sum.\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\frac{\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&=\n",
    "\\phi_0\n",
    "\\prod_{i = 1}^{M}\n",
    "\\phi_i^{w_i}\n",
    "\\phi_i^{\\prime 1 - w_i}\n",
    "\\\\\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&=\n",
    "\\log\\left(\n",
    "    \\phi_0\n",
    "    \\prod_{i = 1}^{M}\n",
    "    \\phi_i^{w_i}\n",
    "    \\phi_i^{\\prime 1 - w_i}\n",
    "\\right)\n",
    "\\\\\n",
    "&=\n",
    "\\log\\phi_0\n",
    "+\n",
    "\\sum_{i = 1}^M\n",
    "    w_i \\log\\phi_i\n",
    "    +\n",
    "    (1 - w_i) \\log\\phi_i^\\prime\n",
    "\\\\\n",
    "&=\n",
    "\\left(\n",
    "    \\log\\phi_0 + \\sum_{i = 1}^M \\log\\phi_i^\\prime\n",
    "\\right)\n",
    "+\n",
    "\\sum_{i = 1}^M\n",
    "    w_i (\\log\\phi_i - \\log\\phi_i^\\prime)\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the log odds is a linear function. In fact, let me replace the $\\phi_0, \\phi_i, \\phi_i^\\prime$ with some new parameters:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\theta_0\n",
    "&=\n",
    "\\log\\phi_0 + \\sum_{i = 1}^M \\log\\phi_i^\\prime\n",
    "\\\\\n",
    "\\theta_i\n",
    "&=\n",
    "\\log\\phi_i - \\log\\phi_i^\\prime\n",
    "\\end{align}\n",
    "\\\\]\n",
    "\n",
    "In this case, then:\n",
    "\n",
    "\\\\[\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\phi}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\phi}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\theta_0\n",
    "+ \\sum_{i=1}^M w_i \\theta_i\n",
    "\\\\]\n",
    "\n",
    "I will not forget about the $\\phi$ values entirely. I will instead just try to pick the best $\\theta$. For any setting of $\\theta$, there is a setting of $\\phi$ that corresponds to that $\\theta$. So by thinking of this problem as *parameterized* by $\\theta$ really doesn't change anything. This is called *reparameterization*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Reparameterized Problem\n",
    "\n",
    "I now want to choose $\\theta$ to maximize:\n",
    "\n",
    "\\\\[\n",
    "\\pprob{\\phi}{\\mathcal{D}}\n",
    "=\n",
    "\\prod_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\pprob{\\theta}{\\text{S} = s_i \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\\\]\n",
    "\n",
    "By definition,\n",
    "\n",
    "\\\\[\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "=\n",
    "\\theta_0\n",
    "+ \\sum_{i=1}^M w_i \\theta_i\n",
    "\\\\]\n",
    "\n",
    "It's a little tricky to write the likelihood function in terms of these log odds. Let me instead make a note: maximizing the probability of something is the same as maximizing the odds, right? So let's try to maximize:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\\prod_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = s_i \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 - s_i \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\prod_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "    }{\n",
    "        \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "    }\n",
    "\\right)^{s_i}\n",
    "\\left(\n",
    "    \\frac{\n",
    "        \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "    }{\n",
    "        \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "    }\n",
    "\\right)^{1 - s_i}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you remember how I hate optimizing products, right? Let's take the log of this formula:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "&\n",
    "\\log\\left(\n",
    "    \\prod_{\n",
    "        ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "    }\n",
    "    \\left(\n",
    "        \\frac{\n",
    "            \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "        }{\n",
    "            \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "        }\n",
    "    \\right)^{s_i}\n",
    "    \\left(\n",
    "        \\frac{\n",
    "            \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "        }{\n",
    "            \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "        }\n",
    "    \\right)^{1 - s_i}\n",
    "\\right)\n",
    "&\n",
    "\\\\\n",
    "&=\n",
    "\\sum_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "s_i\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "+\n",
    "(1 - s_i)\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&\n",
    "\\end{align}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood In Terms of $\\theta$\n",
    "\n",
    "Now, let's not lose sight of our goal. It is to maximize:\n",
    "\n",
    "\\\\[\n",
    "\\pprob{\\theta}{\\mathcal{D}}\n",
    "=\n",
    "\\prod_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\pprob{\\theta}{\\text{S} = s_i \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\\\]\n",
    "\n",
    "I've changed how I parameterize this problem, but I haven't really fundamentally changed anything. My goal remains the same.\n",
    "\n",
    "I need to write this likelihood function directly in terms of $\\theta$ so I can try to optimize it. Before I do that, let me change this into a sum by considering the *log likelihood*:\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\log \\pprob{\\theta}{\\mathcal{D}}\n",
    "&=\n",
    "\\log \\left(\n",
    "    \\prod_{\n",
    "        ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "    }\n",
    "    \\pprob{\\theta}{\\text{S} = s_i \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\right)\n",
    "\\\\\n",
    "&=\n",
    "\\sum_{\n",
    "    ((w_{i, 1}, \\ldots w_{i, M}), s_i) \\in \\mathcal{D}\n",
    "}\n",
    "\\log \\pprob{\\theta}{\\text{S} = s_i \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's see how to turn a log odds back into a probability.\n",
    "\n",
    "\\\\[\n",
    "\\begin{align}\n",
    "\\log\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&=\n",
    "\\theta_0\n",
    "+ \\sum_{i=1}^M w_i \\theta_i\n",
    "\\\\\n",
    "\\exp\\left(\n",
    "    \\log\n",
    "    \\frac{\n",
    "        \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "    }{\n",
    "        \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "    }\n",
    "\\right)\n",
    "&=\n",
    "\\exp\\left(\n",
    "    \\theta_0\n",
    "    + \\sum_{i=1}^M w_i \\theta_i\n",
    "\\right)\n",
    "\\\\\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\pprob{\\theta}{\\text{S} = 0 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}\n",
    "&=\n",
    "\\exp\\left(\n",
    "    \\theta_0\n",
    "    + \\sum_{i=1}^M w_i \\theta_i\n",
    "\\right)\n",
    "\\\\\n",
    "\\frac{\n",
    "    \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "}{\n",
    "    \\left(1 - \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\\right)\n",
    "}\n",
    "&=\n",
    "\\exp\\left(\n",
    "    \\theta_0\n",
    "    + \\sum_{i=1}^M w_i \\theta_i\n",
    "\\right)\n",
    "\\\\\n",
    "\\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "&=\n",
    "\\left(\n",
    "    1 - \\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\right)\n",
    "\\exp\\left(\n",
    "    \\theta_0\n",
    "    + \\sum_{i=1}^M w_i \\theta_i\n",
    "\\right)\n",
    "\\\\\n",
    "\\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "\\left(\n",
    "    1\n",
    "    +\n",
    "    \\exp\\left(\n",
    "        \\theta_0\n",
    "        + \\sum_{i=1}^M w_i \\theta_i\n",
    "    \\right)\n",
    "\\right)\n",
    "&=\n",
    "\\exp\\left(\n",
    "    \\theta_0\n",
    "    + \\sum_{i=1}^M w_i \\theta_i\n",
    "\\right)\n",
    "\\\\\n",
    "\\pprob{\\theta}{\\text{S} = 1 \\condbar W_1 = w_1, \\ldots, W_M = w_M}\n",
    "&=\n",
    "\\frac{\n",
    "    \\exp\\left(\n",
    "        \\theta_0\n",
    "        + \\sum_{i=1}^M w_i \\theta_i\n",
    "    \\right)\n",
    "}{\n",
    "    1\n",
    "    +\n",
    "    \\exp\\left(\n",
    "        \\theta_0\n",
    "        + \\sum_{i=1}^M w_i \\theta_i\n",
    "    \\right)\n",
    "}\n",
    "\\end{align}\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (default)",
   "language": "python",
   "name": "conda-default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
